<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[记一次生产故障排查]]></title>
    <url>%2F2019%2F10%2F13%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%94%9F%E4%BA%A7%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[前言收到生产某服务多台机器报警，cpu飙到100%，系统无法正常提供服务。故开始排查问题。 分析一、分析cpu过高的原因tomcat进出把cpu占满了cpu。使用命令top top -H -p pid查到tomcat进程中相应的线程。将查到的线程号转成十六进制printf &quot;%x\n&quot; tid。然后使用命令jstack pid | tid -A 50查看线程快照。判断是因为频繁full gc引起的cpu飙高。 二、分析频繁full gc的原因首先先查看了jvm的堆内存配置。整个堆内存约为5.5个G，其中青年代分了3个G，老年代分了2.5个G。 再使用命令jstat -gcutil pid 1000查看每秒钟内存各区域占比和gc情况。发现S0、Eden和老年代已经被占满，导致一直full gc，并且每次full gc之后内存都没有被释放掉。内存释放不掉，服务很容易就OOM了。 为了方便分析排查，立刻保存了线程快照和堆dump。命令：jstack -l pid &gt; jstack.log、jmap -dump:format=b,file=temp.dump pid。保留完现场之后，先将几台问题机器重启，防止起OOM，保障服务的暂时可用。将dump下载到本地进行分析。 三、离线dump分析使用jdk自带的VisualVM分析dump。但是由于dump文件有7G多，因此使用命令jvisualvm -J-Xms1024m -J-Xmx2048m打开。 发现OrderAndPrice对象有11万多个实例，感觉非常的可疑。OrderAndPrice是个聚合对象，OrderDetail、OrderPreprice等都是其的属性。OrderAndPrice保存了订单的详细信息，查库获得。查看OrderAndPrice的实例，发现它被一个HashMap引用，而这个Map中竟然有一百万多个项，占用了1G多的内存。 原来这个Map是Mybatis的一级缓存。当我们使用Mybatis进行数据库的操作时候，会创建一个SqlSession来进行一次数据库的会话，会话结束则关闭SqlSession对象。MyBatis一级缓存的生命周期和SqlSession一致。MyBatis一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。所以才会出现有100多万个项的巨大Map。 查看线程快照，定位到了相关的代码。在代码中发现对于String的非空判断使用的是jdk中的Strings.isNullOrEmpty()方法。该方法不能判断空格这样的空字符串，导致全表扫描。修改代码，替换成common3中的StringUtils.isNotBlank()方法。修复代码之后，发布上线解决问题。 123public static boolean isNullOrEmpty(@Nullable String string) &#123; return string == null || string.length() == 0; // string.isEmpty() in Java 6&#125; 解决1、配置Mybatis一级缓存范围。因为Mybatis一级缓存无法关闭，但是可以配置其缓存范围。减少缓存对象的数量和缓存时间。 123&lt;!-- SESSION，缓存会话内的所有sql语句结果 --&gt;&lt;!-- STATEMENT，每次查询结束都会清掉一级缓存 --&gt;&lt;setting name="localCacheScope" value="STATEMENT"/&gt; 2、修改bug代码，防止全表扫描。 引用 https://tech.meituan.com/2018/01/19/mybatis-cache.html]]></content>
      <categories>
        <category>故障</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>故障</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda、Stream]]></title>
    <url>%2F2018%2F12%2F13%2FJDK1-8%2F</url>
    <content type="text"><![CDATA[Lambda语法 参数类型省略–绝大多数情况，编译器都可以从上下文环境中推断出lambda表达式的参数类型。 123456(param1,param2, ..., paramN) -&gt; &#123; statment1; statment2; // ...... return statmentN;&#125; 当lambda表达式的参数个数只有一个，可以省略小括号 123456param1 -&gt; &#123; statment1; statment2; // ...... return statmentN;&#125; 当lambda表达式只包含一条语句时，可以省略大括号、return和语句结尾的分号。 1param1 -&gt; statment 方法引用。 objectName::instanceMethod ClassName::staticMethod ClassName::instanceMethod 构造引用。 ClassName::new 参数lambda表达式其实是快速创建SAM接口的语法糖，原先的SAM接口都可以访问接口外部变量，因此lambda表达式也是可以访问外部变量的，不过lambda表达式访问外部变量有一个非常重要的限制：变量不可变。 在lambda中，this不是指向lambda表达式产生的那个SAM对象，而是声明它的外部对象。 Stream语法 红色框中的语句是一个Stream的生命开始的地方，负责创建一个Stream实例；绿色框中的语句是赋予Stream灵魂的地方，把一个Stream转换成另外一个Stream，红框的语句生成的是一个包含所有nums变量的Stream，经过绿框的filter方法以后，重新生成了一个过滤掉原nums列表所有null以后的Stream；蓝色框中的语句是丰收的地方，把Stream的里面包含的内容按照某种算法来汇聚成一个值。 创建Stream 通过Stream接口的静态工厂方法 通过Collection接口的默认方法 转换Stream distinct：对于Stream中包含的元素进行去重操作（去重逻辑依赖元素的equals方法），新生成的Stream中没有重复的元素。 1234// 去重public List&lt;Integer&gt; distinct(List&lt;Integer&gt; list) &#123; return list.stream().distinct().collect(Collectors.toList());&#125; filter：对于Stream中包含的元素使用给定的过滤函数进行过滤操作，新生成的Stream只包含符合条件的元素。 1234// 过滤list，保留所有大于0的元素public List&lt;Integer&gt; filter(List&lt;Integer&gt; list) &#123; return list.stream().filter(i -&gt; i &gt; 0).collect(Collectors.toList());&#125; map: 对于Stream中包含的元素使用给定的转换函数进行转换操作，新生成的Stream只包含转换生成的元素。 1234// 将list中的元素转换为大写public List&lt;String&gt; toUpperCase(List&lt;String&gt; list) &#123; return list.stream().map(String::toUpperCase).collect(Collectors.toList());&#125; flatMap：和map类似，不同的是其每个元素转换得到的是Stream对象，会把子Stream中的元素压缩到父集合中。 peek: 生成一个包含原Stream的所有元素的新Stream，同时会提供一个消费函数（Consumer实例），新Stream每个元素被消费的时候都会执行给定的消费函数。 limit: 对一个Stream进行截断操作，获取其前N个元素，如果原Stream中包含的元素个数小于N，那就获取其所有的元素。 skip: 返回一个丢弃原Stream的前N个元素后剩下元素组成的新Stream，如果原Stream中包含的元素个数小于N，那么返回空Stream。 聚合Stream聚合数据流操作。在创建和转换阶段并不会对流数据进行处理，而是在合并阶段一次性处理。 collect: 收集数据到新的容器 123public List&lt;String&gt; collect(List&lt;Integer&gt; list) &#123; return list.stream().map(Object::toString).collect(Collectors.toList());&#125; reduce: 汇聚，可以从一组元素中生成一个值 1234// 求和public Integer sum(List&lt;Integer&gt; list) &#123; return list.stream().reduce(0 /*初始值*/, (sum /*中间值*/, num /*当前值*/) -&gt; sum + num);&#125; count: 计数 123public Long count(List&lt;Integer&gt; list) &#123; return list.stream().count();&#125; forEach: 遍历流 123public void forEach(List&lt;Integer&gt; list) &#123; list.forEach(System.out::println);&#125; findFirst: 返回第一项，返回Optional对象 123public Optional findFirst(List&lt;Integer&gt; list) &#123; return list.stream().findFirst();&#125; findAny: 返回任意一项，返回Optional对象 123public Optional findAny(List&lt;Integer&gt; list) &#123; return list.stream().findAny();&#125; allMatch: 所有元素全部匹配 123public Boolean allMatch(List&lt;Integer&gt; list) &#123; return list.stream().allMatch(i -&gt; i &gt; 0);&#125; noneMatch: 所以元素全部不匹配 123public Boolean noneMatch(List&lt;Integer&gt; list) &#123; return list.stream().noneMatch(i -&gt; i &gt; 0);&#125; anyMatch: 任意一个元素匹配 123public Boolean anyMatch(List&lt;Integer&gt; list) &#123; return list.stream().anyMatch(i -&gt; i &gt; 0);&#125;]]></content>
      <categories>
        <category>jdk</category>
      </categories>
      <tags>
        <tag>jdk</tag>
        <tag>Lambda</tag>
        <tag>Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代理与AOP]]></title>
    <url>%2F2018%2F10%2F17%2F%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[代理代理模式是一种设计模式，提供了对目标对象额外的访问方式，即通过代理对象访问目标对象，这样可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。简言之，代理模式就是设置一个中间代理来控制访问原目标对象，以达到增强原对象的功能和简化访问方式。 举个例子，我们生活中经常到火车站去买车票，但是人一多的话，就会非常拥挤，于是就有了代售点，我们能从代售点买车票了。这其中就是代理模式的体现，代售点代理了火车站对象，提供购买车票的方法。 静态代理这种代理方式需要代理对象和目标对象实现一样的接口。 角色 Subject：被代理的接口，定义了方法DoAction()； 12345public interface Subject &#123; void doAction();&#125; RealSubject：原对象，真正的业务实现类，实现了Subject接口； 12345678public class RealSubject implements Subject &#123; @Override public void doAction() &#123; System.out.println("RealSubject is doing..."); &#125;&#125; Proxy：代理类，代理原对象，实现了Subject接口。 12345678910111213141516public class Proxy implements Subject &#123; private RealSubject subject; public Proxy(RealSubject subject) &#123; this.subject = subject; &#125; @Override public void doAction() &#123; System.out.println("Proxy is doing before"); subject.doAction(); System.out.println("Proxy is doing after"); &#125;&#125; 优劣优点 可以在不修改目标对象的前提下扩展目标对象的功能。 缺点 冗余，由于代理对象要实现与目标对象一致的接口，会产生过多的代理类； 不易维护，一旦接口增加方法，目标对象与代理对象都要进行修改。 动态代理动态代理是在实现阶段不用关心代理谁，而在运行阶段才动态的指定代理哪一个对象。 jdkjdk中使用到了一个接口InvocationHandler和一个代理类Proxy ，这两个类配合使用实现了动态代理的功能。InvocationHandler 并实现它的invoke方法，然后再用Proxy的工厂方法newProxyInstance()创建一个代理对象，这个对象同样可以实现对具体类的代理功能。而且想代理哪个具体类，只要给Handler（以下代码中的Invoker）的构造器传入这个具体对象的实例就可以了。 示例 123456789public interface IGamePlayer &#123; void login(String user, String password); void killBoss(); void upgrade();&#125; 123456789101112131415161718public class GamePlayer implements IGamePlayer &#123; @Override public void login(String user, String password) &#123; System.out.println("login, user:" + user + ", password:" + password); &#125; @Override public void killBoss() &#123; System.out.println("kill boss"); &#125; @Override public void upgrade() &#123; System.out.println("upgrade"); &#125;&#125; 1234567891011121314151617public class GamePlayerIH implements InvocationHandler &#123; private IGamePlayer gamePlayer; public GamePlayerIH(IGamePlayer gamePlayer) &#123; this.gamePlayer = gamePlayer; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("before"); Object invoke = method.invoke(gamePlayer, args); System.out.println("after"); return invoke; &#125;&#125; 1234567891011121314public class DynamicProxy &#123; public static void main(String[] args) &#123; IGamePlayer gamePlayer = new GamePlayer(); GamePlayerIH handler = new GamePlayerIH(gamePlayer); IGamePlayer gamePlayerProxy = (IGamePlayer) Proxy.newProxyInstance(GamePlayer.class.getClassLoader(), GamePlayer.class.getInterfaces(), handler); gamePlayerProxy.login("root", "123"); gamePlayerProxy.killBoss(); gamePlayerProxy.upgrade(); &#125;&#125; 原理InvocationHandler接口InvocationHandler接口只定义了一个invoke()方法。通过InvocationHandler接口，所有方法都由该Handler来进行处理，即所有被代理的方法都由InvocationHandler接管实际的处理任务。 12public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; proxy:代理类对象; method:代理类调用的具体方法； args:方法的参数。 Proxy类Proxy类提供创建动态代理类和实例的static方法，并且通过这些方法创建所有动态代理类的父类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException&#123; Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * Look up or generate the designated proxy class. * 查找或生成代理类 */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * Invoke its constructor with the designated invocation handler. */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; /* * 生成代理对象；在代理对象中调用了handler的invoke()方法 */ return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125;&#125; cglibcglib是一个强大的、高性能的代码生成库。它被广泛使用在基于代理的AOP框架提供方法拦截。在实现内部，CGLIB库使用了ASM这一个轻量但高性能的字节码操作框架来转化字节码，产生新类。 AOPTODO]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>代理模式</tag>
        <tag>动态代理</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Paxos算法]]></title>
    <url>%2F2018%2F10%2F02%2FPaxos%2F</url>
    <content type="text"><![CDATA[Paxos算法Paxos算法是一种基于消息传递且具有高度容错性的一致性算法，是最有效的解决分布式一致性问题的算法之一。 参与角色 Proposer： 倡议者可以提出提案以供投票表决 Acceptor：提案接收者，并可以进行投票表决 Learner：提案接受者，没有投票权 条件 一个Acceptor必须批准它收到的第一个提案 如果一个提案[M，V]被选定后，那么之后任何Proposer产生的编号更高的提案，其Value值都为V 算法陈述Paxos算法需要一个类似于两阶段提交的执行过程。 阶段一 Proposer选择一个提案编号M，然后向Acceptor的某个超过半数的子集成员发送编号为M的Prepare请求。 如果一个Acceptor收到一个编号为M的Prepare请求，且编号M大于该Acceptor已经响应的所有Prepare请求的编号，那么它就会将它已经批准过的最大编号的提案作为响应反馈给Proposer，同时该Acceptor会承诺不会再批准任何编号小于M的提案。 阶段二 如果Proposer收到来自半数以上Acceptor对其发出编号为M的Prepare请求的响应后，那么它就会发送一个针对[M，V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的值，如果响应中不包含任何提案，那么V就由Proposer自己决定。 如果Acceptor收到一个针对[M，V]提案的Accept请求，只要该Acceptor没有对编号大于M的Prepare请求做出过响应，它就接受该提案。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Paxos</tag>
        <tag>分布式一致性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于RocketMQ]]></title>
    <url>%2F2018%2F10%2F01%2FRocketMQ%2F</url>
    <content type="text"><![CDATA[架构图 NameServerNameServer是RocketMQ的名称服务器，主要负责对Topic和路由信息的管理。各个角色的组件都需要定期向NameServer上报自己的状态，超时不上报的话，NameServer会认为某个机器出现了故障，其他组件会把这个机器从可用列表中移除。 特点 NameServer集群中各节点之间互不通信，其他组件同时向所以NameServer上报信息； NameServer中管理的数据全部保存在内存当中，不会持久化存储； 如果中途所有NameServer全都挂了，只会影响到路由信息的更新，不会影响客户端和Broker的通信。 BrokerBroker是RocketMQ的核心。主要负责接收Producer发送的消息、处理Consumer的消费请求、消息的持久化和消息的HA机制等。 消息存储 顺序写磁盘以一种恒定的速度旋转。为了读和写，磁头必须定位于指定的磁道，才能开始读写操作。磁头定位到磁道所需的时间称为寻道时间，事实证明这个时间很难减少；执行读写操作的时间称为传送时间。顺序写的方式，节省了寻道时间，相比较于随机写提高了磁盘IO的读写性能。 mmapLinux操作系统分为内核态和用户态，常采用IO缓冲技术提高IO性能。即： 从磁盘复制数据到内核态内存； 从内核态内存复制到用户态内存； 因此一次IO读写过程，需要进行四次的数据拷贝。 而通过mmap的方式，把文件的内容被映像到计算机虚拟内存的一块区域，不需要进行多余的拷贝，这样就可以直接操作内存当中的数据而无需操作的时候每次都通过I/O去物理硬盘写文件的。详情请看文章：MappedByteBuffer。 实现CommitLog类负责Broker中的消息存储。CommitLog类中维护了一个映射文件队列mappedFileQueue。mappedFileQueue队列中记录了消息持久化的磁盘的文件信息MappedFile，每个文件默认大小1G。CommitLog调用putMessage方法存储消息，获取最新的MappedFile，再通过MappedByteBuffer将消息写进MappedFile的内存映射。MappedFile中记录了最新的写入位置wrotePosition，保证文件的顺序写入。同时在CommitLog类中，还维护了一个独立的线程flushCommitLogService，执行刷盘操作，将内存映射中的数据写入磁盘。 刷盘在RocketMQ当中支持两种刷盘方式。 同步刷盘：消息写入内存映射中之后，立刻通知刷盘线程刷盘，然后等待刷盘完成；刷盘完成之后，返回消息写入成功； 异步刷盘：消息写入内存映射之后，返回写入成功。当内存中消息积累到一定程度时，唤醒刷盘线程，统一出发写磁盘的操作。 实现1234567891011121314151617181920212223242526272829public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) &#123; // Synchronization flush if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123; final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; if (messageExt.isWaitStoreMsgOK()) &#123; //之所以阻塞是因为request中有闭锁，当GroupCommitService从队列中取出request并执行完刷盘之后，闭锁释放 GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); //将请求放入requestsWrite的list中 service.putRequest(request); //阻塞闭锁，等待刷盘结束 boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); if (!flushOK) &#123; log.error("do groupcommit, wait for flush failed, topic: " + messageExt.getTopic() + " tags: " + messageExt.getTags() + " client address: " + messageExt.getBornHostString()); putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); &#125; &#125; else &#123; service.wakeup(); &#125; &#125; // Asynchronous flush else &#123; if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123; flushCommitLogService.wakeup(); &#125; else &#123; commitLogService.wakeup(); &#125; &#125;&#125; 主从同步RocketMQ的Broker分为Master和Slave两个角色。Master提供读写服务，而Slave只提供读服务。因此，在Master接收到消息后，要把消息同步到Slave上，这样一旦Master宕机，Slave依然可以提供服务。 实现Slave通过HAClient类向Master报告当前的偏移量，并接收Master的同步数据，写入CommitLog完成同步。 Master会为每个Slave创建一个HAConnection连接。HAConnection中维护了两个线程： ReadSocketService：处理Slave发送的同步请求，接收Slave的偏移量； WriteSocketService：根据Slave的偏移量获取需要同步数据的位置，从CommitLog中加载数据传输给Slave。 分类主从同步分为： 同步复制方式：Master接收到消息之后，立即同步给Slave，Master和Slave均写入成功之后返回； 异步复制方式：只要Master写入成功之后就返回成功，由同步线程异步执行同步操作。 最佳实践需要合理的设置刷盘方式和主从复制方式。通常情况下，应该把Master和Slave配置成ASYNC_FLUSH（异步刷盘），主从之间配置成SYNC_MASTER（同步复制）的方式，这样即使有一台机器出故障，仍然能保证数据不丢失。]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[握手和挥手]]></title>
    <url>%2F2018%2F09%2F27%2F%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[三次握手TCP是主机对主机层的传输控制协议，提供可靠的连接服务，采用三次握手确认建立一个连接。 （1）第一次握手：建立连接时，客户端A发送SYN包（SYN=j）到服务器B，并进入SYN_SEND状态，等待服务器B确认。 （2）第二次握手：服务器B收到SYN包，必须确认客户A的SYN（ACK=j+1），同时自己也发送一个SYN包（SYN=k），即SYN+ACK包，此时服务器B进入SYN_RECV状态。 （3）第三次握手：客户端A收到服务器B的SYN＋ACK包，向服务器B发送确认包ACK（ACK=k+1），此包发送完毕，客户端A和服务器B进入ESTABLISHED状态，完成三次握手。 完成三次握手，客户端与服务器开始传送数据。 四次挥手由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。 CP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)。客户端或服务器均可主动发起挥手动作，在socket编程中，任何一方执行close()操作即可产生挥手操作。 （1）客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送。 （2）服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。和SYN一样，一个FIN将占用一个序号。 （3）服务器B关闭与客户端A的连接，发送一个FIN给客户端A。 （4）客户端A发回ACK报文确认，并将确认序号设置为收到序号加1。 tcp的6种标志位的分别代表： SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急)]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>握手</tag>
        <tag>挥手</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多路复用]]></title>
    <url>%2F2018%2F09%2F27%2F%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%2F</url>
    <content type="text"><![CDATA[文件描述符Linux 系统中，把一切都看做是文件，当进程打开现有文件或创建新文件时，内核向进程返回一个文件描述符，文件描述符就是内核为了高效管理已被打开的文件所创建的索引，用来指向被打开的文件，所有执行I/O操作的系统调用都会通过文件描述符。 多路复用I/O多路复用通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪，就是这个文件描述符进行读写操作之前），能够通知程序进行相应的读写操作。但select()，poll()，epoll()本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 select原理select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。 缺陷 select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。 poll原理poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 poll没有最大连接数的限制，原因是它是基于链表来存储的。 缺陷 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 epoll原理相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。 优点 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 区别支持一个进程所能打开的最大连接数 FD剧增后带来的IO效率问题 消息传递方式]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>多路复用</tag>
        <tag>select</tag>
        <tag>poll</tag>
        <tag>epoll</tag>
        <tag>文件描述符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机监控工具]]></title>
    <url>%2F2018%2F09%2F04%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[jps显示系统内所有虚拟机进程。 选项 作用 -q 只输出LVMID，省略主类的名称 -m 输出虚拟机进程启动时传递给主类main()函数的参数 -l 输出主类的全名，如果进程执行的是jar包，输出jar路径 -v 输出虚拟机进程启动时jvm参数 12345678[root ~]$ jps -l87799 org.apache.catalina.startup.Bootstrap319117 org.apache.catalina.startup.Bootstrap182013 com.creditease.mscp.boot.MSCPBoot241863 org.apache.catalina.startup.Bootstrap262825 org.apache.catalina.startup.Bootstrap82480 org.apache.catalina.startup.Bootstrap261415 sun.tools.jps.Jps jstat用于收集虚拟机各方面的运行数据。 选项 作用 -class 监视类的装载、卸载数量以及类的装载总空间和耗费时间等 -gc 监视Java堆，包含eden、2个survivor区、old区和永久带区域的容量、已用空间、GC时间合计等信息 -gccapcity 监视内容与-gc相同，但输出主要关注Java区域用到的最大和最小空间 -gcutil 监视内容与-gc相同，但输出主要关注已使用空间占总空间的百分比 -gccause 与-gcutil输出信息相同，额外输出导致上次GC产生的原因 -gcnew 监控新生代的GC情况 -gcnewcapacity 与-gcnew监控信息相同，输出主要关注使用到的最大和最小空间 -gcold 监控老生代的GC情况 -gcoldcapacity 与-gcold监控信息相同，输出主要关注使用到的最大和最小空间 -gcpermcapacity 输出永久带用到的最大和最小空间 -compiler 输出JIT编译器编译过的方法、耗时信息 -printcompilation 输出已经被JIT编译的方法 123[weblogic@vm-10-112-180-180 ~]$ jstat -gc 87799 S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT 13056.0 13056.0 301.9 0.0 104960.0 15747.8 3014656.0 791584.0 131072.0 83501.8 2786 23.422 0 0.000 23.422 S0C 当前survivor space 0 的总容量 (KB) S1C 当前survivor space 1 的总容量 (KB) S0U 当前survivor space 0 已使用的容量 (KB) S1U 当前survivor space 1 已使用的容量 (KB) EC 当前 eden space 总容量 (KB) EU 当前eden space已经使用的容量 (KB) OC 当前 old space 总容量 (KB) OU 当前old space 已使用容量(KB) PC 当前 permanent space 总容量(KB) PU 当前 permanent space 已使用容量 (KB) YGC 从应用启动时到现在，年轻代young generation 发生GC Events的总次数 YGCT 从应用启动时到现在， 年轻代Young generation 垃圾回收的总耗时 FGC 从应用启动时到现在， full GC事件总次数 FGCT 从应用启动时到现在， Full sc总耗时 GCT 从应用启动时到现在， 垃圾回收总时间. GCT=YGCT+FGCT jinfo显示虚拟机配置信息。实时的查看和调整JVM的各项参数。可以使用-flag [+/-]name或者-flag name=value修改一部分运行期可写的虚拟机参数。 输出gc日志 123D:\&gt;jinfo -flag +PrintGCDetails 4192D:\&gt;jinfo -flag +PrintGC 4192 jmap生成虚拟机的内存转储快照（heapdump文件） 选项 作用 -dump 生产Java堆转储快照。格式为：-dump[live, ]format=b, file=。其中live子参数说明是否只dump存活的对象。 -finalizerinfo 显示在F-Queue中等待finalizer线程执行finalize方法的对象。只在Linux/Solaris平台下有效。 -heap 显示Java堆详细信息，如使用哪种回收器、参数配置、分代情况等。只在Linux/Solaris平台下有效。 -histo 显示堆中对象统计信息，包括类、实例数量、合计容量。-histo:live，这个命令执行，JVM会先触发gc，然后再统计信息。 -permstat 以Classloader为统计口径显示永久代内存状态。只在Linux/Solaris平台下有效。 -F 当虚拟机进程对-dump选项没有响应时，可使用这个选项强制生产dump快照。只在Linux/Solaris平台下有效。 12345678910[root]$ jmap -dump:format=b,file=dump.hprof 182013Dumping heap to /app/weblogic/pop-interface/logs/dump.hprof ...Heap dump.hprof file created[root]$ lltotal 133652drwxr-xr-x 2 weblogic weblogic 40960 May 17 07:10 bak-rw-rw-r-- 1 weblogic weblogic 42591197 May 17 15:56 catalina.2018-05-17.out-rw------- 1 weblogic weblogic 92541638 May 17 15:57 dump.hprof-rw-rw-r-- 1 weblogic weblogic 1638325 May 17 15:56 gc.log-rw-rw-r-- 1 weblogic weblogic 23925 May 17 15:57 localhost_access_log.2018-05-17.log 可以使用jvisualvm来分析生产的dump文件。 jstack显示虚拟机上的线程快照。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的就定位线程出现长时间停顿的原因，如线程死锁、死循环等。 1jstack pid jcmd在JDK1.7以后，新增了一个命令行工具 jcmd。他是一个多功能的工具，可以用它来导出堆、查看Java进程、导出线程信息、执行GC、还可以进行采样分析。 1jcmd -l #查看所有的进程列表信息。类似jps 1jcmd pid help #列出当前运行的java进程可以执行的操作，详细操作请看下表 常用命令 详情 举例 VM.unlock_commercial_features 取消锁定商业功能。 jcmd pid VM.unlock_commercial_features JFR.start 启动jfr。开启去必须线取消锁定商业功能。 jcmd pid JFR.start name=abc,duration=120s JFR.dump 等待至少duration后，执行命令（注意，文件名必须为.jfr后缀），使用jmc打开生成的jfr文件。 jcmd pid JFR.dump name=abc,duration=120s filename=abc.jfr JFR.stop 停止jfr。 jcmd pid JFR.stop name=abc,duration=120s JFR.check 检查JFR状态。 jcmd pid JFR.check name=abc,duration=120s GC.class_histogram 查看系统中类统计信息。这里和jmap -histo pid的效果是一样的。这个可以查看每个类的实例数量和占用空间大小。 jcmd pid GC.class_histogram Thread.print 查看线程堆栈信息。该命令jstack命令。 jcmd pid Thread.print GC.heap_dump 查看 JVM 的Heap Dump。跟 jmap命令：jmap -dump:format=b,file=heapdump.phrof pid 效果一样。导出的 dump 文件，可以使用MAT 或者 Visual VM 等工具进行分析。 jcmd pid GC.heap_dump dump.hprof VM.system_properties 查看 JVM 的属性信息。 jcmd pid VM.system_properties VM.flags 查看 JVM 的启动参数。 jcmd pid VM.flags VM.command_line 查看 JVM 的启动命令行。 jcmd pid VM.command_line GC.run_finalization 执行一次finalization操作，相当于执行java.lang.System.runFinalization()。 jcmd pid GC.run_finalization GC.run 对 JVM 执行 java.lang.System.gc()。告诉垃圾收集器打算进行垃圾收集，而垃圾收集器进不进行收集是不确定的。 jcmd pid GC.run PerfCounter.print 查看 JVM 性能相关的参数。 jcmd pid PerfCounter.print VM.version 查看目标jvm进程的版本信息。 jcmd pid VM.version 实践查看GC log12342018-06-04T16:12:17.393+0800: 336894.721: [GC2018-06-04T16:12:17.393+0800: 336894.721: [ParNew: 1677824K-&gt;7137K(1887488K), 0.0167290 secs] 2058871K-&gt;388184K(3984640K), 0.0172050 secs] [Times: user=0.10 sys=0.00, real=0.02 secs] 2018-06-04T16:12:39.083+0800: 336916.411: [Full GC2018-06-04T16:12:39.083+0800: 336916.411: [CMS: 381047K-&gt;380283K(2097152K), 1.3115720 secs] 481767K-&gt;380283K(3984640K), [CMS Perm : 171267K-&gt;171267K(285428K)], 1.3120450 secs] [Times: user=1.31 sys=0.00, real=1.31 secs] [ParNew（使用ParNew作为年轻代的垃圾回收期）: 43296K（年轻代垃圾回收前的大小）-&gt;7006K（年轻代垃圾回收以后的大小）(47808K)（年轻代的总大小）, 0.0136826 secs（回收时间）] 44992K（堆区垃圾回收前的大小）-&gt;8702K（堆区垃圾回收后的大小）(252608K)（堆区总大小）, 0.0137904 secs（回收时间）] [Times: user=0.03（Young GC用户耗时） sys=0.00（Young GC系统耗时）, real=0.02 secs（Young GC实际耗时）] 高CPU占用一个应用占用CPU很高，除了确实是计算密集型应用之外，通常原因都是出现了死循环或者是因为内存不足和导致频繁的full gc。 1、查看当前cpu的使用情况top命令 2、查看当前pid下的线程情况ps -mp pid -o THREAD,tid,time 3、将线程id转换为16进制printf “%x\n” tid 4、打印线程快照信息jstack pid |grep tid -A 30 高内存占用1、查看当前内存的使用情况命令top 2、查看当前内存活跃的对象和占用内存大小jmap -histo:live pid]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[disruptor]]></title>
    <url>%2F2018%2F08%2F31%2Fdisruptor%2F</url>
    <content type="text"><![CDATA[RingBufferRingBuffer，即环形的缓冲区。RingBuffer底层是使用数组结构实现的，因为数组对处理器的缓存机制更加友好。同时，为了避免垃圾回收，在数组初始化后就创建event填充数组。 指针偏移RingBuffer拥有一个序号，这个序号指向数组中下一个可用的元素。随着你不停地填充这个buffer，这个序号会一直增长，直到绕过这个环。所以，必须根据序号来确定元素在数组中的位置。 取模取模是最简单最常用的方法。通过序号对数组长度取模来确定元素在数组中的位置。 1index = sequence mod array.length 例如：数组长度为8，序号为12，则元素位于12 % 8 = 4。 位运算disruptor中则使用了更高效的方式计算，位运算。RingBuffer中的素质数组长度必须为2^n，通过位运算，加快定位的速度。下标采取递增的形式。不用担心index溢出的问题。index是long类型，即使100万QPS的处理速度，也需要30万年才能用完。 1index = sequence &amp; (array.length - 1) 例如：数组长度为8，序号为12，则元素位于12 &amp; (8 - 1) = 4。 SequenceSequence是RingBuffer中的指针序号类，通过顺序递增的序号来编号管理通过其进行交换的数据。使用被volatile修饰的long值来记录序号。通过CAS操作来保证并发。并通过填充缓存行来提供性能，防止伪共享。关于CPU缓存行及伪共享，请阅读CPU缓存文章。 SequencerSequencer是Disruptor 的真正核心。此接口有两个实现类 SingleProducerSequencer、MultiProducerSequencer，它们定义在生产者和消费者之间快速、正确地传递数据的并发算法。其巧妙的无锁设计，是Disruptor高性能的关键。 每个生产者或者消费者线程，会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据。整个过程通过原子变量CAS，保证操作的线程安全。 一个生产者写数据生产者单线程写数据的流程比较简单： 申请写入m个元素； 若是有m个元素可以写入，则返回最大的序列号。这儿主要判断是否会覆盖未读的元素； 若是返回的正确，则生产者开始写入元素。 多个生产者多个生产者的情况下，会遇到“如何防止多个线程重复写同一个元素”的问题。Disruptor的解决方法是，每个线程获取不同的一段数组空间进行操作。这个通过CAS很容易达到。只需要在分配元素的时候，通过CAS判断一下这段空间是否已经分配出去即可。 但是会遇到一个新问题：如何防止读取的时候，读到还未写的元素。Disruptor在多个生产者的情况下，引入了一个与Ring Buffer大小相同的buffer：available Buffer。当某个位置写入成功的时候，便把availble Buffer相应的位置置位，标记为写入成功。读取的时候，会遍历available Buffer，来判断元素是否已经就绪。 读数据生产者多线程写入的情况会复杂很多： 申请读取到序号n； 若writer cursor &gt;= n，这时仍然无法确定连续可读的最大下标。从reader cursor开始读取available Buffer，一直查到第一个不可用的元素，然后返回最大连续可读元素的位置； 消费者读取元素。 如下图所示，读线程读到下标为2的元素，三个线程Writer1/Writer2/Writer3正在向RingBuffer相应位置写数据，写线程被分配到的最大元素下标是11。 读线程申请读取到下标从3到11的元素，判断writer cursor&gt;=11。然后开始读取availableBuffer，从3开始，往后读取，发现下标为7的元素没有生产成功，于是WaitFor(11)返回6。 然后，消费者读取下标从3到6共计4个元素。 写数据多个生产者写入的时候： 申请写入m个元素； 若是有m个元素可以写入，则返回最大的序列号。每个生产者会被分配一段独享的空间； 生产者写入元素，写入元素的同时设置available Buffer里面相应的位置，以标记自己哪些位置是已经写入成功的。 如下图所示，Writer1和Writer2两个线程写入数组，都申请可写的数组空间。Writer1被分配了下标3到下表5的空间，Writer2被分配了下标6到下标9的空间。 Writer1写入下标3位置的元素，同时把available Buffer相应位置置位，标记已经写入成功，往后移一位，开始写下标4位置的元素。Writer2同样的方式。最终都写入完成。 WaitStrategy定义Consumer如何进行等待下一个事件的策略。 名称 措施 适用场景 BlockingWaitStrategy 加锁 CPU资源紧缺，吞吐量和延迟并不重要的场景 BusySpinWaitStrategy 自旋 通过不断重试，减少切换线程导致的系统调用，而降低延迟。推荐在线程绑定到固定的CPU的场景下使用 PhasedBackoffWaitStrategy 自旋 + yield + 自定义策略 CPU资源紧缺，吞吐量和延迟并不重要的场景 SleepingWaitStrategy 自旋 + yield + sleep 性能和CPU资源之间有很好的折中。延迟不均匀 TimeoutBlockingWaitStrategy 加锁，有超时限制 CPU资源紧缺，吞吐量和延迟并不重要的场景 YieldingWaitStrategy 自旋 + yield + 自旋 性能和CPU资源之间有很好的折中。延迟比较均匀 使用样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class DisruptorDemo&#123; public static void main(String[] args) throws Exception &#123; // 队列中的元素 class Element &#123; private int value; public int get()&#123; return value; &#125; public void set(int value)&#123; this.value= value; &#125; &#125; // 生产者的线程工厂 ThreadFactory threadFactory = new ThreadFactory()&#123; @Override public Thread newThread(Runnable r) &#123; return new Thread(r, "simpleThread"); &#125; &#125;; // RingBuffer生产工厂,初始化RingBuffer的时候使用 EventFactory&lt;Element&gt; factory = new EventFactory&lt;Element&gt;() &#123; @Override public Element newInstance() &#123; return new Element(); &#125; &#125;; // 处理Event的handler EventHandler&lt;Element&gt; handler = new EventHandler&lt;Element&gt;()&#123; @Override public void onEvent(Element element, long sequence, boolean endOfBatch) &#123; System.out.println("Element: " + element.get()); &#125; &#125;; // 阻塞策略 BlockingWaitStrategy strategy = new BlockingWaitStrategy(); // 指定RingBuffer的大小 int bufferSize = 16; // 创建disruptor，采用单生产者模式 Disruptor&lt;Element&gt; disruptor = new Disruptor(factory, bufferSize, threadFactory, ProducerType.SINGLE, strategy); // 设置EventHandler disruptor.handleEventsWith(handler); // 启动disruptor的线程 disruptor.start(); RingBuffer&lt;Element&gt; ringBuffer = disruptor.getRingBuffer(); for (int l = 0; true; l++) &#123; // 获取下一个可用位置的下标 long sequence = ringBuffer.next(); try &#123; // 返回可用位置的元素 Element event = ringBuffer.get(sequence); // 设置该位置元素的值 event.set(l); &#125; finally &#123; ringBuffer.publish(sequence); &#125; Thread.sleep(10); &#125; &#125;&#125;]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>性能</tag>
        <tag>RingBuffer</tag>
        <tag>伪共享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络模型]]></title>
    <url>%2F2018%2F08%2F26%2F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[ISO/OSI七层网络模型 物理层物理层包括物理传输介质（电缆或无线介质），任何网络都必须使用传输介质来发送和接收信号，这些信号构成了网络通信的物理表示。物理层的任务就是建立、维持和断开网络连接。 数据链路层数据链路层的任务是，在发送方确保实现物理层数据的可靠传输；在接收方检验锁收到的数据的可靠性。 网络层网络层的主要功能是对Internet上的每一台主机提供一个全球唯一的地址，并提供主机之间的通信路径。 传输层传输层的任务就是确保从发送方到接收方数据的可靠的端到端传输。为了确保这一功能的实现，传输层包含了端到端的错误检测和错误恢复数据。 会话层会话层是在发送方和接收方之间进行通信时创建、维持、之后终止或断开连接的地方。 表示层 表示层提供格式化的表示和转换数据服务。数据的压缩和解压缩， 加密和解密等工作都由表示层负责。 应用层应用层主要定义了应用程序能够从网络上请求使用的几种类型服务，并且规定了在从应用程序接收消息或向应用程序发送消息时，数据所必须采用的格式。 TCP/IP四层网络模型网络接口层网络接口层，又可叫物理链路层，与OSI参考模型中的物理层和数据链路层相对应，它负责监视数据在主机和网络之间的交换。 网络通信就是把有特定意义的数据通过物理介质传送给对方，单纯的发送 0 和 1 是没有意义的，要传输有意义的数据，就需要以字节为单位对 0 和 1 进行分组，并且要标识好每一组电信号的信息特征，然后按照分组的顺序依次发送。以太网规定一组电信号就是一个数据包，一个数据包被称为一帧， 制定这个规则的协议就是以太网协议。一个完整的以太网数据包如下图所示： 整个数据帧由首部、数据和尾部三部分组成，首部固定为14个字节，包含了目标MAC地址、源MAC地址和类型；数据最短为46个字节，最长为1500个字节，如果需要传输的数据很长，就必须分割成多个帧进行发送；尾部固定为4个字节，表示数据帧校验序列，用于确定数据包在传输过程中是否损坏。因此，以太网协议通过对电信号进行分组并形成数据帧，然后通过物理介质把数据帧发送给接收方。那么以太网如何来识接收方的身份呢？ 以太网规协议定，接入网络的设备都必须安装网络适配器，即网卡， 数据包必须是从一块网卡传送到另一块网卡。而网卡地址就是数据包的发送地址和接收地址，也就是帧首部所包含的MAC地址，MAC地址是每块网卡的身份标识，就如同我们身份证上的身份证号码，具有全球唯一性。MAC地址采用十六进制标识，共6个字节， 前三个字节是厂商编号，后三个字节是网卡流水号，例如 4C-0F-6E-12-D2-19 有了MAC地址以后，以太网采用广播形式，把数据包发给该子网内所有主机，子网内每台主机在接收到这个包以后，都会读取首部里的目标MAC地址，然后和自己的MAC地址进行对比，如果相同就做下一步处理，如果不同，就丢弃这个包。 所以链路层的主要工作就是对电信号进行分组并形成具有特定意义的数据帧，然后以广播的形式通过物理介质发送给接收方。 网际层网际层，又可叫网络层。对应OSI参考模型的网络层，主要解决主机到主机的通信问题。 对于上面的过程，有几个细节问题值得我们思考： 发送者如何知道接收者的MAC地址？ 发送者如何知道接收者和自己同属一个子网？ 如果接收者和自己不在同一个子网，数据包如何发给对方？ 为了解决这些问题，网络层引入了三个协议，分别是IP协议、ARP协议、路由协议。 IP协议通过前面的介绍我们知道，MAC地址只与厂商有关，与所处的网络无关，所以无法通过MAC地址来判断两台主机是否属于同一个子网。 因此，网络层引入了IP协议，制定了一套新地址，使得我们能够区分两台主机是否同属一个网络，这套地址就是网络地址，也就是所谓的IP地址。 IP地址目前有两个版本，分别是IPv4和IPv6，IPv4是一个32位的地址，常采用4个十进制数字表示。IP协议将这个32位的地址分为两部分，前面部分代表网络地址，后面部分表示该主机在局域网中的地址。由于各类地址的分法不尽相同，以C类地址192.168.24.1为例，其中前24位就是网络地址，后8位就是主机地址。因此， 如果两个IP地址在同一个子网内，则网络地址一定相同。为了判断IP地址中的网络地址，IP协议还引入了子网掩码， IP地址和子网掩码通过按位与运算后就可以得到网络地址。 由于发送者和接收者的IP地址是已知的(应用层的协议会传入)， 因此我们只要通过子网掩码对两个IP地址进行AND运算后就能够判断双方是否在同一个子网了。 ARP协议即地址解析协议，是根据IP地址获取MAC地址的一个网络层协议。其工作原理如下： ARP首先会发起一个请求数据包，数据包的首部包含了目标主机的IP地址，然后这个数据包会在链路层进行再次包装，生成以太网数据包，最终由以太网广播给子网内的所有主机，每一台主机都会接收到这个数据包，并取出标头里的IP地址，然后和自己的IP地址进行比较，如果相同就返回自己的MAC地址，如果不同就丢弃该数据包。ARP接收返回消息，以此确定目标机的MAC地址；与此同时，ARP还会将返回的MAC地址与对应的IP地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。cmd输入 arp -a 就可以查询本机缓存的ARP数据。 路由协议通过ARP协议的工作原理可以发现，ARP的MAC寻址还是局限在同一个子网中，因此网络层引入了路由协议，首先通过IP协议来判断两台主机是否在同一个子网中，如果在同一个子网，就通过ARP协议查询对应的MAC地址，然后以广播的形式向该子网内的主机发送数据包；如果不在同一个子网，以太网会将该数据包转发给本子网的网关进行路由。网关是互联网上子网与子网之间的桥梁，所以网关会进行多次转发，最终将该数据包转发到目标IP所在的子网中，然后再通过ARP获取目标机MAC，最终也是通过广播形式将数据包发送给接收方。 而完成这个路由协议的物理设备就是路由器，在错综复杂的网络世界里，路由器扮演者交通枢纽的角色，它会根据信道情况，选择并设定路由，以最佳路径来转发数据包。 IP数据包在网络层被包装的数据包就叫IP数据包，IPv4数据包的结构如下图所示： IP数据包由首部和数据两部分组成，首部长度为20个字节，主要包含了目标IP地址和源IP地址，目标IP地址是网关路由的线索和依据；数据部分的最大长度为65515字节，理论上一个IP数据包的总长度可以达到65535个字节，而以太网数据包的最大长度是1500个字符，如果超过这个大小，就需要对IP数据包进行分割，分成多帧发送。 所以，网络层的主要工作是定义网络地址，区分网段，子网内MAC寻址，对于不同子网的数据包进行路由。 传输层传输层对应OSI参考模型的传输层，为应用层实体提供端到端的通信功能，保证了数据包的顺序传送及数据的完整性。 链路层定义了主机的身份，即MAC地址， 而网络层定义了IP地址，明确了主机所在的网段，有了这两个地址，数据包就从可以从一个主机发送到另一台主机。但实际上数据包是从一个主机的某个应用程序发出，然后由对方主机的应用程序接收。而每台电脑都有可能同时运行着很多个应用程序，所以当数据包被发送到主机上以后，是无法确定哪个应用程序要接收这个包。 因此传输层引入了UDP协议来解决这个问题，为了给每个应用程序标识身份，UDP协议定义了端口，同一个主机上的每个应用程序都需要指定唯一的端口号，并且规定网络中传输的数据包必须加上端口信息。 这样，当数据包到达主机以后，就可以根据端口号找到对应的应用程序了。UDP定义的数据包就叫做UDP数据包，结构如下所示： UDP数据包由首部和数据两部分组成，首部长度为8个字节，主要包括源端口和目标端口；数据最大为65527个字节，整个数据包的长度最大可达到65535个字节。 UDP协议比较简单，实现容易，但它没有确认机制， 数据包一旦发出，无法知道对方是否收到，因此可靠性较差，为了解决这个问题，提高网络可靠性，TCP协议就诞生了，TCP即传输控制协议，是一种面向连接的、可靠的、基于字节流的通信协议。简单来说TCP就是有确认机制的UDP协议，每发出一个数据包都要求确认，如果有一个数据包丢失，就收不到确认，发送方就必须重发这个数据包。 为了保证传输的可靠性，TCP 协议在 UDP 基础之上建立了三次对话的确认机制，也就是说，在正式收发数据前，必须和对方建立可靠的连接。由于建立过程较为复杂，我们在这里做一个形象的描述： 主机A：我想发数据给你，可以么？ 主机B：可以，你什么时候发？ 主机A：我马上发，你接着！ 经过三次对话之后，主机A才会向主机B发送正式数据，而UDP是面向非连接的协议，它不与对方建立连接，而是直接就把数据包发过去了。所以 TCP 能够保证数据包在传输过程中不被丢失，但美好的事物必然是要付出代价的，相比 UDP，TCP 实现过程复杂，消耗连接资源多，传输速度慢。 TCP 数据包和 UDP 一样，都是由首部和数据两部分组成，唯一不同的是，TCP 数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常 TCP 数据包的长度不会超过IP数据包的长度，以确保单个 TCP 数据包不必再分割。 总结一下，传输层的主要工作是定义端口，标识应用程序身份，实现端口到端口的通信，TCP协议可以保证数据传输的可靠性。 应用层 应用层对应OSI参考模型的高层，为用户提供所需要的各种服务。 理论上讲，有了以上三层协议的支持，数据已经可以从一个主机上的应用程序传输到另一台主机的应用程序了，但此时传过来的数据是字节流，不能很好的被程序识别，操作性差。因此，应用层定义了各种各样的协议来规范数据格式，常见的有 HTTP、FTP、SMTP 等，HTTP 是一种比较常用的应用层协议，主要用于B/S架构之间的数据通信。在 Resquest Headers 中，Accept 表示客户端期望接收的数据格式，而 ContentType 则表示客户端发送的数据格式；在 Response Headers 中，ContentType 表示服务端响应的数据格式，这里定义的格式，一般是和 Resquest Headers 中 Accept 定义的格式是一致的。 有了这个规范以后，服务端收到请求以后，就能正确的解析客户端发来的数据，当请求处理完以后，再按照客户端要求的格式返回，客户端收到结果后，按照服务端返回的格式进行解析。 所以应用层的主要工作就是定义数据格式并按照对应的格式解读数据。]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>网络模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存屏障]]></title>
    <url>%2F2018%2F08%2F24%2F%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[指令执行顺序顺序执行在早期处理器中，处理器执行指令的顺序就是按照我们编写汇编代码的顺序执行的。按序执行对于早期处理器而言是一种行之有效的方案，但随着对时间的要求，我们希望上述过程能够在最短的时间内执行完成，这就促使人们迫切希望找到一种优化指令执行过程的方案 。 乱序执行随着处理器流水线技术和多核技术的发展，目前的高级处理器通过提高内部逻辑元件的利用率来提高运行速度，通常会采用乱序执行技术。打乱机器指令的顺序，就算指令位于后边，只要可以执行，就先执行，这就是乱序执行。 乱序执行的重要概念是实现了避免计算机在用于运算的对象不可获取时的大量等待。 在现代计算机中，处理器的运算速度大大超越了内存速度，所以在顺序执行处理器等待数据的过程中，乱序执行处理器能够执行大量的指令。 内存屏障内存屏障是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。大多数现代计算机为了提高性能而采取乱序执行，这使得内存屏障成为必须。 作用当基于共享可变状态的内存操作被重新排序时，程序可能行为不定。一个线程写入的数据可能被其他线程可见，原因是数据 写入的顺序不一致。适当的放置内存屏障通过强制处理器顺序执行待定的内存操作来避免这个问题。 内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。 分类 读屏障：在读指令之前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据； 写屏障：在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存； 性能内存屏障阻碍了CPU采用优化技术来降低内存操作延迟，会造成一定的性能损失。 Java内存模型volatileJava内存模型中，当把变量声明为volatile类型后，会volatile变量在写操作之后会插入一个store屏障，在读操作之前会插入一个load屏障。因此不会将该变量上的操作与其他内存操作一起重排序，保证了volatile变量的可见性。 final一个类的final字段会在初始化后插入一个store屏障，来确保final字段在构造函数初始化完成并可被使用时可见。]]></content>
      <categories>
        <category>操作系统原理</category>
      </categories>
      <tags>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群分区设计]]></title>
    <url>%2F2018%2F08%2F22%2F%E9%9B%86%E7%BE%A4%E5%88%86%E5%8C%BA%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[哈希取模分区使用特点的数据，再根据节点数量取模，决定映射到哪个节点上。 缺点 当数据扩容或收缩时，数据节点的映射关系需要重新计算，会导致数据的重新迁移 一致性哈希分区为系统中每个节点分配一个token，范围一般在0～2^32，这些token构成一个哈希环。当要根据某个key查找对应的节点时，先根据key计算哈希值，然后顺时针找到第一个token大于等于该哈希值的节点。 优点 添加或删除节点时，只影响哈希环中相邻节点，对其他节点无影响 哈希槽分区Redis集群采用哈希槽分区实现。在Redis的每个节点上都会存储哈希槽信息。根据这些信息，可以找到每个节点负责的哈希槽，进而找到数据所在的节点。当我们提供一个key时，redis会根据CRC16的算法算出一个结果，然后把结果除以16384求余数，这样每个关键词都会对应一个编号为0-16384的哈希槽，通过这个值找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>hash</tag>
        <tag>分区</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于分布式缓存的高可用]]></title>
    <url>%2F2018%2F08%2F22%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[缓存迁移处理分布式缓存迁移是比较困难的，通常我们将其分为平滑迁移和停机迁移。 平滑迁移步骤 双写 迁移历史数据 切读 下线双写 1、双写按照新规则和旧规则同事往新缓存和旧缓存中写数据。 2、迁移历史数据评估需要迁移的历史数据。在某些场景下，通过数据库回溯数据，不断有新数据写入新的缓存，历史数据会逐渐过时，在一定时间之后，新的集群中自然就有了最新的数据，也就不在需要迁移历史数据了。 3、切读把应用层所有的读操作路由到新的缓存集群上。 4、下线双写关闭双写开关，把写入旧集群的逻辑下线。 停机迁移步骤 停应用 迁移历史数据 更改数据源配置 重启应用 这种方式的好处是实现简单、高效，能够有效的避免数据不一致，但需要有停止服务，一般在晚上交易量小或者非核心服务的场景下使用。 缓存防灾缓存穿透缓存穿透指的是使用不存在的Key进行大量的高并发访问，这导致缓存无法命中，每次请求都要穿透到后端数据库进行查询，使数据库的压力过大，操作数据库的性能下降。 解决思路 缓存空值，当再次接收到同样的查询请求时，直接返回空值； 对参数进行校验，拦截参数不合法的无效请求 缓存并发缓存并发的问题通常发生在高并发的场景下，当一个缓存key过期时，因为访问这个缓存的key请求量过大，多个请求同事发现缓存过期，因此多个请求会同事访问数据库来查询最新的数据，并且写回缓存，当访问数据库的请求过大时，会造成数据库的性能下降。 解决思路 使用分布式锁，只让一个线程去访问数据库，并回写缓存，其余线程等待或立即返回空值； 软过期，不适用缓存服务器提供的过期时间，而是由业务程序判断是否过期并更新。 缓存雪崩缓存服务器重启或大量缓存集中在某一个时间段内失效，给后端数据库造成瞬时的负载升高的压力，压垮数据库。 解决思路 对不同的数据，设置不同的过期时间。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>高可用</tag>
        <tag>迁移</tag>
        <tag>容灾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分库分表]]></title>
    <url>%2F2018%2F08%2F21%2F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[切分方式垂直切分把单一的表拆分成多个表，并分散到不同的数据库（主机）上。一个数据库由很多表的构成，每个表对应着不同的业务，垂直切分是指按照业务将表进行分类，分布到不同的数据库上面，这样也就将数据或者说压力分担到不同的库上面。 水平切分相对于垂直拆分，水平拆分不是将表做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中。 分库分表的核心思路就是将原本保存在单表中太大的数据进行拆分，将这些数据分散保存到多个数据库的多个表中，避免因为单表数据太大给数据库的访问带来的读写性能问题。 分片规则 按照 ID 求模，将数据分散到不同的数据库，具有相同数据用户的数据都被分散到一个库中。 按照日期，将不同月甚至日的数据分散到不同的库中。 按照某个特定的字段求摸，或者根据特定范围段分散到不同的库中。 执行过程 分片优化 合理的制定分片规则，将数据尽可能平均的拆分 通过索引或异构索引表，降低全表扫描频率 聚合数据量大、计算量大的数据，可以通过将数据迁移到HBase或ES等NoSQL来查询 异构索引表异构索引表，即采用异步机制将原表内的每一次创建和更新，都换另一个维度保存一份完整的数据表或索引表。例如：应用在创建或更新一条按照订单ID为分库分表键的订单数据时，也会再保存一份按照买家ID为分库分表键的订单索引数据。这样当以用户ID为条件查询订单时，可有效的避免多库多表的全表扫描。 实现方式： 应用层通过异步的手段自己实现，容易引发分布式事务的问题 数据层通过中间件采用数据复制的方式实现，例如：canal]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>分库分表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读写分离]]></title>
    <url>%2F2018%2F08%2F21%2F%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[所有写操作必须对应到主库，读操作可以在主库和从库机器上进行。主库与从库的结构完全一样，一个主库可以有多个从库。读写分离的方式可以有效的提高数据库集群的吞吐量。 常见的主从模型： 主-主-从 主-从-从 问题 主从不同步。所有的写操作在主库中执行，然后异步的更新到从库上。所以从主库同步到从库，有一定的延迟。当系统繁忙时，延迟问题会更加严重。从库机器数量的增加也会使这个问题更严重。 主库是集群的瓶颈，当写操作过多时会严重影响主库的稳定性，如果主库挂掉，则整个集群都将不能正常工作。 最佳实践 当读操作压力大时，可以考虑添加从库来分解大量读操作带来的压力，但当从库达到一定的数量时，就需要考虑分库来缓解压力了。 当写的压力大时，就必须进行分库操作了。 集群中机器的性能不一，某些性能高，某些性能低。这时需要设置读写比重来达到负载均衡。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>读写分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[引用]]></title>
    <url>%2F2018%2F08%2F21%2F%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[强引用强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。 1Object o=new Object(); // 强引用 软引用软引用是用来描述一些有用但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。 12String str=new String("abc"); // 强引用 SoftReference&lt;String&gt; softRef=new SoftReference&lt;String&gt;(str); // 软引用 弱引用弱引用是用来描述非必需对象的，单是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。 12String str=new String("abc"); WeakReference&lt;String&gt; abcWeakRef = new WeakReference&lt;String&gt;(str); 虚引用虚引用是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收是收到一个系统通知。]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>引用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC优化]]></title>
    <url>%2F2018%2F08%2F21%2FGC%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[通过收集GC信息，结合系统需求，明确性能目标（例如：停顿时间、GC时间在整个时间所占用的百分比），确定优化方案。例如选用合适的GC回收器、重新设置内存比例、调整JVM参数等。 调整堆的大小选择堆的大小其实是一种平衡。如果分配的堆过小，则程序的大部分时间可能都消耗在GC上，没有足够的时间去运行应用程序的逻辑。如果分配的堆过大，GC停顿消耗的时间取决于堆的大小，堆越大，停顿时间可能越长。设置堆内存的大小，不能超过系统内存的容量。否则操作系统会使用磁盘来充当不足的那部分内存，会导致性能的严重下降。 命令 说明 -Xms 设置老年代初始值 -Xmx 设置老年代最大值 -Xmn 设置青年代内存大小 -Xss 设置每个线程的堆栈大小。默认为1M。 设置内存比例各分区的大小对GC的性能影响很大。如何将各分区调整到合适的大小，分析活跃数据的大小是很好的切入点。 活跃数据的大小是指，应用程序稳定运行时长期存活对象在堆中占用的空间大小，也就是Full GC后堆中老年代占用空间的大小。可以通过GC日志中Full GC之后老年代数据大小得出，比较准确的方法是在程序稳定后，多次获取GC数据，通过取平均值的方式计算活跃数据的大小。活跃数据和各分区之间的比例关系如下： 空间 倍数 总大小 3-4 倍活跃数据的大小 新生代 1-1.5 活跃数据的大小 老年代 2-3 倍活跃数据的大小 永久代 1.2-1.5 倍Full GC后的永久代空间占用 例如，根据GC日志获得老年代的活跃数据大小为300M，那么各分区大小可以设为： 总堆：1200MB = 300MB × 4 新生代：450MB = 300MB × 1.5 老年代： 750MB = 1200MB - 450MB 这部分设置仅仅是堆大小的初始值，后面的优化中，可能会调整这些值，具体情况取决于应用程序的特性和需求。 命令 说明 -XX:NewSize 设置新生代空间的初始值大小 -XX:MaxNewSize 设置新生代空间的最大大小 -XX:NewRatio 设置新生代占堆内存的比例（young = heap / (1 + NewRatio)），默认为2 永久代与元空间 命令 说明 -XX:MaxPermSize 设置永久代的最大值（jdk1.7） -XX:MetaspaceSize 设置元空间的初始值（jdk1.8） -XX:MaxMetaspaceSize 设置元空间的最大值（jdk1.8） -XX:PermSize 设置永久代的初始值（jdk1.7） 控制并发除Serial收集器之外几乎所有的垃圾收集器使用的算法都基于多线程。合理的设置线程数量，有助于提升垃圾收集的性能。一般情况下，服务器上如果运行了多个JVM实例，则所有JVM实例的垃圾收集线程等于CPU核的数量。 命令 说明 -XX:ParallelGCThreads 设置垃圾收集线程数量]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>GC优化</tag>
        <tag>性能</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制]]></title>
    <url>%2F2018%2F08%2F20%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[虚拟机把Class文件加载到内存，并对其进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是类的加载机制。 类的生命周期 加载1、通过一个类的全限定名来获取定义此类的二进制字节流。 2、将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 3、在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 对于数组类而言，数组类本身不通过类加载器创建，它是由Java虚拟机直接创建的。 验证为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都在方法区中进行分配。仅分配类变量，即static修饰的变量。这里所说的初始值是数据类型的零值。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用：以符号来描述引用的目标。 直接引用：可以直接指向目标的指针、相对偏移量或是能间接定位到目标的句柄。 初始化才真正开始执行类中定义的Java代码。初始化阶段就是执行类构造器 。 类加载器类加载器用于实现类的加载动作。比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义；否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那么这两个类就必定不相等。 类型启动类加载器（Bootstrap ClassLoader）这个类加载器是用C++语言实现的。负责加载存放在&lt;JAVA_HOME&gt;\lib目录中的类库，或者被-Xbootclasspath参数指定路径中的，并且是虚拟机识别的类库。顶层类加载器，没有父类加载器。 扩展类加载器（Extension ClassLoader）这个类加载器是由sun.misc.Launcher$ExtClassLoader实现，它负责加载&lt;JAVA_HOME&gt;/lib/ext目录下或者被java.ext.dirs系统变量所指定位路径中的类库，开发者可以直接使用标准扩展类加载器。它的父类加载器是启动类加载器。 应用类加载器（Application ClassLoader）这个类加载器是由sun.misc.Launcher$AppClassLoader实现。这个类加载器是ClassLoader中getSystemClassLoader()方法的返回值。它负责加载用户类路径上所指定的库类，开发者可以直接使用这个类加载器。它的父类加载器是扩展类加载器。 自定义类加载器开发者自己实现的类加载器。它的父类加载器是应用类加载器。 双亲委派机制 意义防止内存中出现多份同样的字节码。 源码ClassLoader.loadClass() 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; ClassLoader.findClass() 123protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; throw new ClassNotFoundException(name);&#125; 自定义继承ClassLoader，并实现findClass方法。 打破双亲委派机制继承ClassLoader，并实现findClass()和loadClass()方法。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>类加载</tag>
        <tag>双亲委派</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ByteBuf缓冲区]]></title>
    <url>%2F2018%2F08%2F20%2FByteBuf%2F</url>
    <content type="text"><![CDATA[ByteBuf是Netty中实现的字节缓冲区。 工作原理ByteBuf与Java NIO中ByteBuffer最大的不同点点在于，ByteBuffer中只维护了一个索引，因此需要调用flip()方法切换读写模式。而ByteBuf中，维护了两套索引，一个读索引，记录了已读取的位置；另一个写索引，记录了可写的位置。ByteBuf中名称以read或write开头的方法会推进相应的索引，而以set或get开头的不会。可以指定ByteBuf最大的容量，默认是Integer.MAX_VALUE。 上图展示了一个刚初始化的ByteBuf，读索引和写索引的初始值为0。 随着读、写指针的偏移，ByteBuf被分隔成了三个部分。 可丢弃数据：指已经读取过的数据，通过discardReadBytes()方法，可以清空已读的数据。不建议频繁使用。 可读取数据：指未读的数据。 可写入数据：指可写入的空间。]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>buffer</tag>
        <tag>netty</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MappedByteBuffer]]></title>
    <url>%2F2018%2F08%2F20%2FMappedByteBuffer%2F</url>
    <content type="text"><![CDATA[内存管理 MMC：CPU的内存管理单元 物理内存：内存条的内存空间 虚拟内存：计算机系统内存管理的一种技术，它使得应用程序认为它拥有连续的可用内存（一个连续完整的地址空间）；而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换 页面文件：操作系统反映构建并使用虚拟内存的硬盘空间大小而创建的文件 缺页中断：当程序试图访问已映射在虚拟空间中但未被加载到物理内存的一个分页时，由MMC发出中断；如果操作系统判断此次访问是有效的，则尝试将相关的页从虚拟内存文件中载入物理内存 MappedByteBufferMappedByteBuffer继承自ByteBuffer，是java nio引入的文件内存映射方案，读写性能极高。很多高性能Java应用都使用内存映射文件来持久化数据。 常用操作 说明 get 读数据 put 写数据 force 强制将内存中的数据写入文件 slice 缓存区分片 示例123456789101112131415161718192021222324252627public static void main(String[] args) throws HttpProcessException, NoSuchMethodException &#123; File file = new File("E://data.txt"); long len = file.length(); byte[] ds = new byte[(int) len]; try &#123; MappedByteBuffer mappedByteBuffer = new RandomAccessFile(file, "rw") .getChannel() //读写的方式将文件map到虚拟内存 .map(FileChannel.MapMode.READ_WRITE, 0, len); for (int offset = 0; offset &lt; len; offset++) &#123; //从MappedByteBuffer中读数据 byte b = mappedByteBuffer.get(); ds[offset] = b; &#125; System.out.println(new String(ds)); for (int offset = 0; offset &lt; len; offset++) &#123; //往MappedByteBuffer中写数据 mappedByteBuffer.put(offset, ds[(int)len - offset -1]); &#125; //刷新到磁盘 mappedByteBuffer.force(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; FileChannel提供了map方法把文件映射到虚拟内存，通常情况可以映射整个文件，如果文件比较大，可以进行分段映射。MappedByteBuffer继承自ByteBuffer，内部维护了一个逻辑地址address。map0()函数返回一个地址address，这样就无需调用read或write方法对文件进行读写，通过address就能够操作文件。底层采用unsafe.getByte方法，通过（address + 偏移量）获取指定内存的数据。 MapMode类型 MapMode.READ_ONLY：只读，试图修改得到的缓冲区将导致抛出异常。 MapMode.READ_WRITE：读/写，对得到的缓冲区的更改最终将写入文件；但该更改对映射到同一文件的其他程序不一定是可见的。 MapMode.PRIVATE：私用，可读可写,但是修改的内容不会写入文件，只是buffer自身的改变，这种能力称之为”copy on write”。 分析采用内存映射的读写效率要比传统的read/write性能高。 read()是系统调用，首先将文件从硬盘拷贝到内核空间的一个缓冲区，再将这些数据拷贝到用户空间，实际上进行了两次数据拷贝。而map()也是系统调用，但没有进行数据拷贝，直接将文件从硬盘拷贝到用户空间，只进行了一次数据拷贝。 注意 MappedByteBuffer使用虚拟内存，因此分配(map)的内存大小不受JVM的-Xmx参数限制。 关闭资源。 不要经常调用MappedByteBuffer.force()方法，这个方法强制操作系统将内存中的内容写入硬盘，所以如果你在每次写内存映射文件后都调用force()方法，你就不能真正从内存映射文件中获益，而是跟disk IO差不多。 如果被请求的页面不在内存中，内存映射文件会导致页面错误。 MappedByteBuffer和文件映射在缓存被GC之前都是有效的。sun.misc.Cleaner可能是清除内存映射文件的唯一选择。 MappedByteBuffer与DirectByteBuffer的区别这两种类型的buffer的不同在于：MappedByteBuffers是被操作系统分配在虚拟内存空间；而DirectByteBuffer是被分配在可靠的物理内存中。]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>buffer</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO]]></title>
    <url>%2F2018%2F08%2F20%2FNIO%2F</url>
    <content type="text"><![CDATA[NIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O处理问题的有效方式。 NIO主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector(选择器)。传统IO基于字节流和字符流进行操作，而NIO基于Channel(通道)和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector(选择器)用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个线程可以监听多个数据通道。 常见I/O模型对比 以socket.read()为例子：传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。NIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）。 ChannelChannel(通道)类似流，但又有些不同。 既可以从通道中读取数据，又可以写数据到通道。但流（InputStream和OutputStream） 的读写通常是单向的。 通道可以异步地读写。 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。 Channel的实现FileChannel从文件中读写数据，FileChannel无法设置为非阻塞模式，它总是运行在阻塞模式下。 123456789101112RandomAccessFile read = new RandomAccessFile("a.txt", "r");RandomAccessFile write = new RandomAccessFile("b.txt", "rw");FileChannel readChannel = read.getChannel();FileChannel writeChannel = write.getChannel();ByteBuffer buffer = ByteBuffer.allocate(1024);while (readChannel.read(buffer) != -1) &#123; buffer.flip(); writeChannel.write(buffer); buffer.compact();&#125;readChannel.close();writeChannel.close(); DatagramChannel能通过UDP协议读写网络中的数据。 SocketChannel能通过TCP读写网络中的数据。 ServerSocketChannel可以监听新进来的TCP连接，对每一个新进来的连接都会创建一个SocketChannel。 BufferBuffer缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。 实现 使用方法1、分配内存容量 要想获得一个Buffer对象首先要进行分配。 每一个Buffer类都有一个allocate方法。 1ByteBuffer buf = ByteBuffer.allocate(48); 将字节数组包装成Buffer。 12byte[] bytes = new byte[48];ByteBuffer buf = ByteBuffer.wrap(bytes); 2、写入数据到Buffer当向buffer写入数据时，buffer会记录下写了多少数据。 从channel中读数据写到buffer 1int bytesRead = inChannel.read(buf); 通过put方法写入 1buf.put(127); 3、调用flip()方法将Buffer从写模式切换到读模式。 4、从Buffer中读取数据读取之前写入到buffer的所有数据。 从buffer中读数据写到channel 1int bytesWritten = inChannel.write(buf); 通过get方法读数据 1byte aByte = buf.get(); 5、清空缓冲区 一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。调用clear()方法或者compact()方法。clear()方法会清空整个缓冲区；compact()方法只会清除已经读过的数据。 6、缓冲区切片将当前的position到limit之间的数据分割出来，返回一个新的ByteBuffer。新Buffer与老Buffer共享切分区间内的数据（position到limit之间的数据）。 1ByteBuffer byteBuffer = buf.slice(); 切片源码 12345678public ByteBuffer slice() &#123; return new HeapByteBuffer(hb,//原始字节数组 -1,//新buffer的mark标记位置设为0 0, //新buffer的position位置设为0 this.remaining(),//新buffer的limit等于老buffer的limit-position this.remaining(),//新buffer的capacity等于老buffer的limit-position this.position() + offset);&#125; 工作原理 关键属性capacity缓冲区数组的总长度。 作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。 position下一个要操作的数据元素的位置。 当你写数据到Buffer中时，position表示当前的位置。初始的position值为0。当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。 当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0. 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。 limit缓冲区数组中不可操作的下一个元素的位置：limit&lt;=capacity。 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。 当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）。 mark用于记录当前position的前一个位置或者默认是0。 通过调用Buffer.mark()方法，可以标记Buffer中的一个特定的position，之后可以通过调用Buffer.reset()方法恢复到这个position。Buffer.rewind()方法将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素。 原理说明 1、通过ByteBuffer.allocate(11)方法创建了一个11个byte的数组的缓冲区，初始状态如下图，position的位置为0，capacity和limit默认都是数组长度11。 2、从Channel读取5个字节的数据，并写入Buffer时，此时position的位置为5，capacity和limit不变。 3、当调用flip()方法后，将Buffer转换为读模式，读取Buffer中的数据，此时position的位置为0，limit变为5，capacity不变。 SelectorSelector（选择器）是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。 创建1Selector selector = Selector.open(); 注册1234// channel设置为非阻塞channel.configureBlocking(false); //channel根据感兴趣的状态，注册到selectorSelectionKey key = channel.register(selector, Selectionkey.OP_READ | SelectionKey.OP_WRITE); 就绪的channel123456// 阻塞到至少有一个通道在你注册的事件上就绪了int select();// 和select()一样，除了最长会阻塞timeout毫秒int select(long timeout);// 不会阻塞，不管什么通道就绪都立刻返回int selectNow(); SelectionKeySelectionKey对象是用来跟踪注册事件的句柄。在SelectionKey对象的有效期间，Selector会一直监控与SelectionKey对象相关的事件，如果事件发生，就会把SelectionKey对象加入到selected-keys集合中。 SelectionKey.OP_CONNEC 连接就绪 SelectionKey.OP_ACCEPT 接收就绪 SelectionKey.OP_READ 读就绪 SelectionKey.OP_WRITE 写就绪 例子12345678910111213141516171819202122Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) &#123; int readyChannels = selector.select(); if(readyChannels == 0) continue; Set selectedKeys = selector.selectedKeys(); Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove(); &#125;&#125;]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于锁]]></title>
    <url>%2F2018%2F08%2F18%2F%E9%94%81%2F</url>
    <content type="text"><![CDATA[AQSAQS是AbstractQueuedSynchronizer类的简称，即队列同步器。它是构建锁或者其他同步组件的基础框架。 AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。 AQS 使用一个 volatile int 类型的成员变量 state 来表示同步状态： 当 state &gt; 0 时，表示已经获取了锁。 当 state = 0 时，表示释放了锁。 AQS 通过内置的 FIFO 同步队列来完成资源获取线程的排队工作。如果当前线程获取同步状态失败（锁）时，AQS 则会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程 当同步状态释放时，则会把节点中的线程唤醒，使其再次尝试获取同步状态。 CAS CAS （Compare and Swap），即比较并替换。指的是现代 CPU 广泛支持的一种对内存中的共享数据进行操作的一种特殊指令。这个指令会对内存中的共享数据做原子的读写操作。简单介绍一下这个指令的操作过程：首先，CPU 会将内存中将要被更改的数据与期望的值做比较。然后，当这两个值相等时，CPU 才会将内存中的数值替换为新的值。否则便不做操作。最后，CPU 会将旧的数值返回。这一系列的操作是原子的。 CAS的思想很简单：三个参数，一个当前内存值V、旧的预期值A、即将更新的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做，并返回false。 AtomicInteger中的compareAndSet()方法： 1234 public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; 问题CAS存在一个很明显的问题，即ABA问题。 问题：如果变量V初次读取的时候是A，并且在准备赋值的时候检查到它仍然是A，那能说明它的值没有被其他线程修改过了吗？ 如果在这段期间曾经被改成B，然后又改回A，那CAS操作就会误认为它从来没有被修改过。针对这种情况，java并发包中提供了一个带有标记的原子引用类。 volatilevolatile是一种稍弱的同步机制，用来确保将变量的更新操作通知到其他线程。当把变量声明为volatile类型之后，编译器与运行时都会注意到这个变量是共享的。访问volatile变量时，不会执行加锁操作，因此不会使线程发送阻塞。 volatile变量只能保证内存中的可见性，而不能保证互斥性。根据这个特性，volatile变量常用来表示状态。 synchronized 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象； 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象； 修改一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类的所有对象； 修改一个类，其作用的范围是synchronized后面括号括起来的部分，作用的对象是这个类的所有对象。 synchronized锁是可重入的。synchronized既能保证互斥性，也能保证内存可见性。 LockLock是java中的显示锁。 ReentrantLockReentrantLock实现了Lock接口，并提供了与synchronized相同的互斥性和内存可见性。ReentrantLock锁也是可重入锁。 1234567891011121314public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 公平锁与非公平锁123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 公平锁：线程按照他们发出请求的顺序加入到AQS的等待队列的末尾，依次获取锁 非公平锁： 当一个线程请求非公平锁时，如果在发出请求的同时该锁变成可用状态，那么这个线程会跳过队列中所有的等待线程而尝试获取锁，若获取失败则仍会被加入到等待队列的末尾。 在公平的锁中，如果有另一个线程持有锁或者有其他线程在等待队列中等待这个所，那么新发出的请求的线程将被放入到队列中。而非公平锁上，只有当锁被某个线程持有时，新发出请求的线程才会被放入队列中。 非公平锁的性能要优于公平锁。 读写锁一个资源可以被多个读操作访问，或者被一个写操作访问，但不能两者同时进行。 123456public interface ReadWriteLock &#123; Lock readLock(); Lock writeLock();&#125; 对于在多处理器系统上被频繁读取饿数据结构，读写锁能提高性能；而在其他场景下，读写锁的性能要差于独占锁，因为读写锁的复杂性更高。 synchronized与Lock的比较 类别 synchronized Lock 实现机制 悲观锁 乐观锁 操作层次 Java的关键字，JVM层面 Java代码层面 锁的释放 1、以获取锁的线程执行完同步代码，释放锁；2、线程执行发生异常，jvm会让线程释放锁 在finally中必须释放锁，不然容易造成线程死锁 锁的状态 无法判断 可以判断 锁的类型 互斥性 内存可见性 可重入 不可中断 非公平 互斥性 内存可见性 可重入 可判断 可公平 可非公平 死锁原因 两个线程试图以不同的顺序来获取相同的锁。 四个必要条件 互斥使用，即当资源被一个线程使用(占有)时，别的线程不能使用。 不可抢占，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放。 请求和保持，即当资源请求者在请求其他的资源的同时保持对原有资源的占有。 循环等待，即存在一个等待队列：线程1占有A资源的同时想要获取B资源，而线程2占有B资源的同时想要获取A资源；于是便形成了一个等待队列。 当上述四个条件都成立的时候，便形成死锁。当然，死锁的情况下如果打破上述任何一个条件，便可让死锁消失。 死锁的诊断JVM工具jps -l查看JVM进程 jstack {pid}查看pid进程的堆栈信息 避免死锁的方法定时锁使用Lock类中的定时tryLock功能来代替内置锁。指定一个超时时间，再等待时间超过设置的时间后，返回失败信息或回滚重新尝试获取所有锁；避免永远等待，造成死锁。 分布式锁redis实现分布式锁 redis通常可以使用setnx来实现分布式锁。setnx来创建一个key，并设置过期时间。如果key不存在则创建成功返回1，如果key已经存在则返回0。依照上述来判定是否获取到了锁获取到锁的执行业务逻辑，完毕后删除lock_key，来实现释放锁其他未获取到锁的则进行不断重试，直到自己获取到了锁 1234567891011121314151617public void lock()&#123; while(true)&#123; ret = set lock_key identify_value nx ex lock_timeout if(ret)&#123; //获取到了锁 return; &#125; sleep(100); &#125;&#125;public void release()&#123; value = get lock_key if(identify_value == value)&#123; del lock_key &#125;&#125; 问题1、 lock timeout的存在也使得失去了锁的意义，即存在并发的现象。一旦出现锁的租约时间，就意味着获取到锁的客户端必须在租约之内执行完毕业务逻辑，一旦业务逻辑执行时间过长，租约到期，就会引发并发问题。所以有lock timeout的可靠性并不是那么的高。 2、 redis单机情况下，还存在redis单点故障的问题。如果为了解决单点故障而使用redis的sentinel或者cluster方案，则更加复杂，引入的问题更多。 死锁如果进程获得锁后，断开了与 Redis 的连接（可能是进程挂掉，或者网络中断），如果没有有效的释放锁的机制，那么其他进程都会处于一直等待的状态，即出现“死锁”。 解决办法在使用 SETNX 获得锁时，我们将键lock的值设置为锁的有效时间，进程获得锁后，其他进程还会不断的检测锁是否已超时，如果超时，那么等待的进程也将有机会获得锁。当前进程需要在超时时退出，否则超时后，其他进程有可能拿到锁导致多个进程同时拿到锁。 当判断锁超时时，我们不能简单地使用 DEL命令删除键lock以释放锁。因为这样会操作多个并发现场依次删除，同时获取锁的情况。例如A线程删除了死锁，并正要设置新的锁，而B进程删除了A新设置的锁，又加了一把新锁。 既然不能删除lock，则可以通过redis的GETSET操作。由于GETSET操作在设置键的值的同时，还会返回键的旧值，通过比较键 lock的旧值是否小于当前时间，可以判断进程是否已获得锁。 ZooKeeper实现分布式锁获取锁 1234567891011121314151617public void lock()&#123; path = 在父节点下创建临时顺序节点 while(true)&#123; children = 获取父节点的所有节点 if(path是children中的最小的)&#123; 代表获取了节点 return; &#125;else&#123; 添加监控前一个节点是否存在的watcher wait(); &#125; &#125;&#125;watcher中的内容&#123; notifyAll();&#125; 释放锁 123public void release()&#123; 删除上述创建的节点&#125; 锁的占用时间限制：redis就有占用时间限制，而ZooKeeper则没有，最主要的原因是redis目前没有办法知道已经获取锁的客户端的状态，是已经挂了呢还是正在执行耗时较长的业务逻辑。而ZooKeeper通过临时节点就能清晰知道，如果临时节点存在说明还在执行业务逻辑，如果临时节点不存在说明已经执行完毕释放锁或者是挂了。 是否单点故障：redis本身有很多中玩法，如客户端一致性hash，服务器端sentinel方案或者cluster方案，很难做到一种分布式锁方式能应对所有这些方案。而ZooKeeper只有一种玩法，多台机器的节点数据是一致的，没有redis的那么多的麻烦因素要考虑。 总体上来说ZooKeeper实现分布式锁更加的简单，可靠性更高。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>锁</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集器]]></title>
    <url>%2F2018%2F08%2F18%2F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[图中展示了7种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。 Serial收集器 这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程（stop the world），直到它收集结束。 特点新生代、老年代都会使用串行回收。 新生代使用复制算法， 老年代使用标记-整理算法。 ParNew收集器 ParNew收集器其实就是Serial收集器的多线程版本。 特点新生代并行，老年代串行。新生代使用复制算法， 老年代使用标记-整理算法。 Parallel Scavenge收集器 Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。其目标是达到一个可控制的吞吐量。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）。所以Parallel Scavenge收集器也被称为“吞吐量优先”的收集器。 特点新生代并行，老年代串行。 Serial Old收集器 Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记－整理算法。 特点新生代串行，老年代串行。 Parallel Old收集器 Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。 特点新生代并行，老年代并行。 CMS收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它是基于“标记—清除”算法实现的。 执行步骤1、初始标记标记GC Roots能直接关联到的对象，速度快。会发生“stop the world”。 2、并发标记GC Roots Tracing。 3、重新标记 修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。会发生“stop the world”。 4、并发清除并发清除对象。 优点 并发收集 低停顿 缺点 对CPU资源非常敏感 无法处理浮动垃圾 “标记-清除”算法会产生大量空间碎片 G1收集器 在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。 执行步骤1、初始标记 初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。 2、并发标记 并发标记阶段是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 3、最终标记最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。 4、筛选回收 筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 常用参数 参数 描述 UseSerialGC 虚拟机运行在Client 模式下的默认值，打开此开关后，使用Serial + Serial Old 的收集器组合进行内存回收。 UseParNewGC 打开此开关后，使用ParNew + Serial Old 的收集器组合进行内存回收。 UseConcMarkSweepGC 打开此开关后，使用ParNew + CMS + Serial Old 的收集器组合进行内存回收。Serial Old 收集器将作为CMS 收集器出现Concurrent Mode Failure失败后的后备收集器使用。 UseParallelGC 虚拟机运行在Server 模式下的默认值，打开此开关后，使用Parallel Scavenge + Serial Old（PS MarkSweep）的收集器组合进行内存回收。 UseParallelOldGC 打开此开关后，使用Parallel Scavenge + Parallel Old 的收集器组合进行内存回收。 SurvivorRatio 新生代中Eden 区域与Survivor 区域的容量比值， 默认为8， 代表 Eden ：Survivor=8∶1。 PretenureSizeThreshold 晋升到老年代的对象年龄。每个对象在坚持过一次Minor GC 之后，年 龄就加1，当超过这个参数值时就进入老年代。 UseAdaptiveSizePolicy 动态调整Java 堆中各个区域的大小以及进入老年代的年龄。 HandlePromotionFailure 是否允许分配担保失败，即老年代的剩余空间不足以应付新生代的整个Eden 和Survivor 区的所有对象都存活的极端情况。 ParallelGCThreads 设置并行GC 时进行内存回收的线程数。 GCTimeRatio GC 时间占总时间的比率，默认值为99，即允许1% 的GC 时间。仅在 使用Parallel Scavenge 收集器时生效。 MaxGCPauseMillis 设置GC 的最大停顿时间。仅在使用Parallel Scavenge 收集器时生效。 CMSInitiatingOccupancyFraction 设置CMS 收集器在老年代空间被使用多少后触发垃圾收集。默认值为68%，仅在使用CMS 收集器时生效。 UseCMSCompactAtFullCollection 设置CMS 收集器在完成垃圾收集后是否要进行一次内存碎片整理。仅在使用CMS 收集器时生效。 CMSFullGCsBeforeCompaction 设置CMS 收集器在进行若干次垃圾收集后再启动一次内存碎片整理。仅在使用CMS 收集器时生效。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>性能</tag>
        <tag>JVM</tag>
        <tag>GC</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集算法]]></title>
    <url>%2F2018%2F08%2F18%2F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[标记-清除算法首先标记出所有需要回收的对象，在标记完成之后统一回收所有被标记的对象。 标记算法引用计数法给对象添加一个引用计数器，每当有一个地方引用它时，计数器加1；当引用失效时，计数器就减1。任何时刻计数器为0的对象就是不能再被使用的。 可达性分析法以一系列的GC Roots对象为起点，从起点开始向下搜索，搜索所有走过的路径称为引用链，当一个对象到GC Roots没有任何引用链时，则证明此对象时不可用的。 在java中，可作为GC Roots的对象有： 虚拟机栈（栈帧中的本地变量表）中引用的对象； 方法区中的类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中JNI（即一般说的Native方法）中引用的对象 标记-清除算法的不足：1、效率问题：标记与清除的效率都不高。 2、空间问题：标记清除之后会产生大量不连续的内存碎片，空间碎片太多会导致以后需要分配大对象时，没有连续的内存空间而不得不提前出发另一次垃圾收集动作。 复制算法将可用的内存按容量划分为大小相等的两块，每次只使用其中一块。当一块内存用完了，就将还存在的对象复制到另一块上面，然后再把已使用过的内存空间一次性清理掉。青年代使用的就是复制算法。 复制算法的不足：将内存一分为二，可使用的内存缩小到了原来的一半，代价太高。 标记-整理算法标记过程与标记-清除算法一致，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 老年代使用的就是标记-整理算法。 分代收集算法根据对象的存活周期不同将内存分为青年代和老年代。 青年代中，每次垃圾收集时都会发现大批对象死去，只有少量存活，因此选用复制算法。将内存分为一块较大的Eden空间和两块较小的Survivor空间，默认比例是8:1。每次使用Eden空间和一块 Survivor空间创建对象。当回收时，将 Eden和 Survivor中还存活的对象一次性复制到另一块 Survivor空间上，最后清理掉 Eden空间和使用过的 Survivor空间。当另一块 Survivor空间不够容纳复制过来的内存时，需要依赖老年代进行分配担保。 老年代对象的存活率较高，因此使用标记-整理算法进行回收。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>性能</tag>
        <tag>JVM</tag>
        <tag>GC</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务]]></title>
    <url>%2F2018%2F08%2F18%2F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[所谓事务是用户定义的一个数据库操作系列，这些操作要么全部执行，要么全部不执行，是一个不可分割的工作单位。 特性原子性事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。 一致性事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。 隔离性多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 持久性一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。 隔离级别冲突问题脏读脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。 不可重复读不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。比如事务A中两处读取数据-total-的值。在第一读的时候，total是100，然后事务B就把total的数据改成200，事务A再读一次，结果就发现，total竟然就变成200了，造成事务A数据混乱。 幻读幻读是指当事务不是独立执行时发生的一种现象。例如事务A读取一条指定where条件的语句，返回结果集。此时事务B插入一行新记录，恰好满足A的where条件。然后A使用相同的条件再次查询，结果集中可以看到B插入的记录，这条新纪录就是幻想。（防不住新增） 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。 隔离级别 READ_UNCOMMITTED读未提交：最低级别，一个事务可以读取另一个未提交事务的数据。幻想读、不可重复读和脏读都允许。 READ_COMMITTED读已提交：一个事务要等另一个事务提交后才能读取数据。允许幻想读、不可重复读，不允许脏读。 REPEATABLE_READ可重复读：在开始读取数据（事务开启）时，不再允许修改操作。允许幻想读，不允许不可重复读和脏读。 SERIALIZABLE可串行化：最高级别，在该级别下，事务串行化顺序执行。幻想读、不可重复读和脏读都不允许。 锁类型悲观锁悲观锁是指假设并发更新冲突会发生，所以不管冲突是否真的发生，都会使用锁机制。 悲观锁根据使用性质，又可以分为： 共享锁（S锁）：对数据进行读操作。因此多个事务可以同时为一个对象加共享锁。 排它锁（X锁）：排他锁表示对数据进行写操作。如果一个事务对对象加了排他锁，其他事务就不能再给它加任何锁了。 排它锁 1SELECT ... FOR UPDATE; 共享锁 1SELECT ... LOCK IN SHARE MODE; 悲观锁根据作用范围，又可以分为： 表锁： 开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 行锁： 开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 页锁： 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 乐观锁乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。 实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。 死锁情景一 一个用户A 访问表A(锁住了表A),然后又访问表B；另一个用户B 访问表B(锁住了表B)，然后企图访问表A；这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了。 原因两个事务以不同的循序来锁住两个相同的表，就有可能会造成死锁。 解决方法这种死锁比较常见，是由于程序的BUG产生的，除了调整的程序的逻辑没有其它的办法。仔细分析程序的逻辑，对于数据库的多表操作时，尽量按照相同的顺序进 行处理，尽量避免同时锁定两个资源，如操作A和B两张表时，总是按先A后B的顺序处理， 必须同时锁定两个资源时，要保证在任何时刻都应该按照相同的顺序来锁定资源。 情景二用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户B里的独占锁由于A 有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升到独占锁也就不可能释放共享锁，于是出现了死锁。这种死锁比较隐蔽，但在稍大点的项目中经常发生。如在某项目中，页面上的按钮点击后，没有使按钮立刻失效，使得用户会多次快速点击同一按钮，这样同一段代码对数据库同一条记录进行多次操作，很容易就出现这种死锁的情况。 原因共享锁与排它锁的特性引起的死锁 解决方法 防止重复提交。可以防止一部分并发的可能。 使用乐观锁进行控制。乐观锁大多是基于数据版本（Version）记录机制实现。即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是 通过为数据库表增加一个“version”字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数 据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。乐观锁机制避免了长事务中的数据库加锁开销（用户A和用户B操作过程中，都没有对数据库数据加锁），大大提升了大并发量下的系统整体性能表现。Hibernate 在其数据访问引擎中内置了乐观锁实现。需要注意的是，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户更新操作不受我们系统的控制，因此可能会造 成脏数据被更新到数据库中。 使用悲观锁进行控制。悲观锁大多数情况下依靠数据库的锁机制实现，如Oracle的Select … for update语句，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。如一个金融系统， 当某个操作员读取用户的数据，并在读出的用户数据的基础上进行修改时（如更改用户账户余额），如果采用悲观锁机制，也就意味着整个操作过程中（从操作员读 出数据、开始修改直至提交修改结果的全过程，甚至还包括操作员中途去煮咖啡的时间），数据库记录始终处于加锁状态，可以想见，如果面对成百上千个并发，这样的情况将导致灾难性的后果。所以，采用悲观锁进行控制时一定要考虑清楚。 情景三如果在事务中执行了一条不满足条件的update语句，则执行全表扫描，把行级锁上升为表级锁，多个这样的事务执行后，就很容易产生死锁和阻塞。类似的情 况还有当表中的数据量非常庞大而索引建的过少或不合适的时候，使得经常发生全表扫描，最终应用系统会越来越慢，最终发生阻塞或死锁。 原因行锁与表锁阻塞。 解决方法使用索引优化，尽量防止全表扫描。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>数据库</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[索引]]></title>
    <url>%2F2018%2F08%2F18%2F%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引原理索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。 类型普通索引这是最基本的MySQL数据库索引，它没有任何限制。 唯一索引索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。 主键索引它是一种特殊的唯一索引，不允许有空值。 主键索引是聚簇索引。聚簇索引是一种对磁盘上实际数据重新组织以按指定的一个或多个列的值排序。由于聚簇索引的索引页面指针指向数据页面，所以使用聚簇索引查找数据几乎总是比使用非聚簇索引快。每张表只能建一个聚簇索引，并且建聚簇索引需要至少相当该表120%的附加空间，以存放该表的副本和索引中间页。 组合索引两个或更多个列上的索引被称作组合索引。 数据结构B-Tree索引B-Tree 索引是 MySQL 数据库中使用最为频繁的索引类型。mysql中B-Tree索引是以B+Tree的结构实现的。索引的检索需要从根节点开始一直到叶子节点才结束。 特点 1、B-Tree索引可以在表达式中使用=, &gt;, &gt;=, &lt;, &lt;=用作列比较或者 BETWEEN 运算符。还能使用LIKE比较，如果参数是一个不以通配符开头的常量。 2、插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。造成IO操作频繁。 3、区间查找可能需要返回上层节点重复遍历，IO操作繁琐。 Hash索引Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。 特点 1、Hash 索引仅仅能满足”=”,”IN”和”&lt;=&gt;”查询，不能使用范围查询。由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。 2、Hash 索引无法被用来避免数据的排序操作。由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算。 3、Hash 索引不能利用部分索引键查询。对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。 4、Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。 R-Tree索引FullText索引最左前缀匹配原则最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 原理当使用B+Tree索引时，b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+树是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道第一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>优化</tag>
        <tag>数据库</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于分布式事务]]></title>
    <url>%2F2018%2F08%2F17%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[分布式事务顾名思义就是在分布式环境下运行的事务，对于分布式事务来说，事务的每个操作步骤是运行在不同机器上的服务的。分布式事务处理的关键是必须有一种方法可以知道事务在任何地方所做的所有动作，提交或回滚事务的决定必须产生统一的结果（全部提交或全部回滚） CAP原则 一致性（C） 可用性（A） 分区容错性（P） 一致性在分布式系统中的所有数据备份，在同一时刻是否同样的值。 强一致性当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP 理论，这种实现需要牺牲可用性。 弱一致性系统并不保证连续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。 最终一致性系统并不保证续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。 可用性在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。、 分区容错性以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。 二阶段提交协议在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有参与者节点的操作结果并最终指示这些节点是否要把操作结果进行真正的提交。因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 准备阶段 提交阶段 准备阶段 协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作） 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 提交阶段如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源) 三阶段提交协议 询问阶段 准备阶段 提交阶段 TCC try：对业务系统进行检查和资源预留 confirm：执行业务并提交 cancel：业务回滚，是否预留资源 TCC协议将一个任务拆分成try，confirm，cancel三个步骤。正常的流程会先执行try，如果执行没问题，则执行confirm；如果执行出现了问题，则执行取消操作cancel。 MQ通过MQ的事务消息来实现分布式事务。其核心思想是让上游事务的执行和MQ服务端的消息能否被投递和消费同时成功或者同时失败，而不会出现本地事务并没有执行成功，但消息已经被订阅方消费的情况。 在执行本地事务之前，发送方先向MQ发送一条事务消息； MQ接收到事务消息之后，会持久化并返回客户端接收成功。此时的消息为半消息，即MQ的订阅方无法感知到该条消息； 发送方执行本地事务，此时会出现两种情况：执行成功、执行失败； 执行成功：向MQ发送commit消息，MQ将消息转为正常的消息，让订阅方消费。执行失败：向MQ发送rollback消息，MQ将删除之前的办消息，订阅方将不会消费消息； 当由于服务宕机或网络抖动等原因，步骤4未成功执行，MQ会定时扫码长时间没有确认的半消息，向发送方确认事务状态； 发送方检查本地事务的执行，向MQ发送commit或rollback消息； 缺点 下游服务器事务执行失败时，此时上游事务已经执行成功，让上游事务进行回滚代价较高。因此，常采用正向补偿的方式，即通过不断重试或人工干预的方式让下游事务执行成功，使整个链路流程继续向前执行，而避免出现回滚。 不适合超过两个以上的事务操作。 最终一致性的最佳实践查询模式任何服务操作都需要提供一个查询接口，用来向外部输出操作执行的状态。服务操作的使用方可以通过查询接口得知服务操作执行的状态，然后根据不同的状态来做不同的处理操作。 补偿模式为了让系统最终达到一致状态而做的努力都叫作补偿。常见的补偿方法： 回滚操作，以达到一致性的目的； 重试机制，例如：记录操作日志，通过异步或者定时抓取的方式来重新执行操作，保证一致性； 定期校对模式各系统在没有达到一致之前，系统间的状态是不一致的。通过第三方核对系统定期的比对状态，当发现有状态不一致的情况后，则通知警报。然后触发补偿机制，修复状态，保持一致性。 三者配合使用。例如：服务调用超时之后，使用查询模式查看目标操作是否成功；如果成功，则返回执行完成；如果没有成功，则触发补偿机制，当补偿机制成功则返回执行完成。同时使用定期校对模式，定期对重要数据进行校对。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>分布式</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序]]></title>
    <url>%2F2018%2F08%2F17%2F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[插入排序插入排序是最简单的排序算法之一。插入排序由N-1次排序组成。每一次插入，都保证数组为已排序状态。 时间复杂度：O(n2)。 实现： 123456789101112131415161718/** * 插入排序 * @param array * @return */private static int[] insertSort(int[] array) &#123; int temp; for (int i = 0; i &lt; array.length; i++) &#123; for (int j = array.length - 1; j &gt; i; j--) &#123; if (array[i] &gt; array[j]) &#123; temp = array[i]; array[i] = array[j]; array[j] = temp; &#125; &#125; &#125; return array;&#125; 希尔排序希尔排序又叫做缩减增量排序，是对插入排序的一种优化算法。它通过比较相距一定间隔的元素来工作；各趟比较所用的距离随着算法的进行而缩小，直到只比较相邻元素的最后一趟排序位置。 实现： 123456789101112131415private static int[] shellSort(int[] array) &#123; for (int i = array.length / 2; i &gt; 0; i /= 2) &#123; //定义步长 for (int j = 0; j &lt; array.length - i; j++) &#123; //从头至尾逐个执行 for (int k = i; k &lt; array.length; k += i) &#123; //所有相隔k的两个元素比较 int temp; if (array[k - i] &gt; array[k]) &#123; temp = array[k - i]; array[k - i] = array[k]; array[k] = temp; &#125; &#125; &#125; &#125; return array;&#125; 堆排序堆排序是基于二叉堆实现的排序算法。其实现思路： 将无序数组中的元素逐个插入二叉堆； 将根节点R从二叉堆中移除到排序的数组，将二叉堆中最后的节点X放置根节点 对X进行下滤，直到二叉堆满足特性之后，重复2操作 当算法终止时，数组则以排好的顺序包含所有元素。 关于二叉堆，请看文章：二叉堆。 归并排序归并排序采用递归分治的方式来实现排序。 将原数组分为左、右两个数组； 分别对左、右两个数组进行排序； 将排序完毕的左、右数组，根据排序规则合并成一个数组。 实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 递归的将数组拆分成左右两个排序好的数组，再合并两个数组 * @param array * @param left * @param right */public void mergeSort(int[] array, int left, int right) &#123; if (left &lt; right) &#123; int center = (right + left) / 2; mergeSort(array, left, center); mergeSort(array, center + 1, right); merge(array, left, center, right); &#125; return;&#125;private void merge(int[] array, int left,int center, int right) &#123; int[] temp = new int[right - left + 1]; int li = left; int ri = center + 1; for (int i = 0; i &lt; temp.length; i++) &#123; if (li &lt; center + 1 &amp;&amp; ri &lt; right + 1) &#123; if (array[li] &lt; array[ri]) &#123; temp[i] = array[li++]; &#125; else &#123; temp[i] = array[ri++]; &#125; &#125; else &#123; if (li &gt; center) &#123; // 左侧的数组已经没有元素了，则将右侧的剩余元素加入temp temp[i] = array[ri++]; &#125; else &#123; // 反之，将左侧的剩余元素加入temp temp[i] = array[li++]; &#125; &#125; &#125; // 将temp中的元素加入array addAll(array, temp, left);&#125;private void addAll(int[] array, int[] temp, int start) &#123; for (int i = 0; i &lt; temp.length; i++) &#123; array[start++] = temp[i]; &#125;&#125; 快速排序原理从一组未排序的元素中，随机选取一个元素，作为枢纽元。然后让剩余的元素与枢纽元进行比较，将集合分为三部分：小于枢纽元的组成一部分，大于枢纽元的组成一部分，最后是枢纽元单独成为一部分。然后在递归的对小集合和大集合再重复此操作，最终完成排序。 实现 选取枢纽元； 随机选取； 三数中值选取，取首、尾和中心的三个元素的中值； 将枢纽元与数组的最后一个元素交换位置； 创建两个指针，指针i指向第一个元素，指针j指向倒数第二个元素； 当i在j的左侧时，将i向右移，移过那些小于枢纽元的元素，停留在大于枢纽元的元素上；同时将j向左移，移过那些大于枢纽元的元素，停留在小于枢纽元的元素上；然后将i上的元素与j上的元素互换位置； 当i与j重合或i在j的右侧时，停止两个指针的移动，并将枢纽元与指针i指向的元素交换位置。 实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public void queckSort(int[] array, int left, int right) &#123; if (left &lt; right) &#123; int median = getMedian(array[left], array[(left + right) / 2], array[right]); // 将中数交换到数组的最后 if (median == array[left]) &#123; array[left] = array[right]; array[right] = median; &#125; else if (median == array[(left + right) / 2]) &#123; array[(left + right) / 2] = array[right]; array[right] = median; &#125; // 比较 int i = left; int j = right - 1; while (true) &#123; while (array[i] &lt; median) &#123; i++; &#125; while (array[j] &gt; median) &#123; j--; &#125; if (i &lt; j) &#123; int temp = array[i]; array[i] = array[j]; array[j] = temp; &#125; else &#123; // 枢纽元与i位置的元素交换 array[right] = array[i]; array[i] = median; break; &#125; &#125; // 递归 queckSort(array, left, i - 1); queckSort(array, i + 1, right); &#125;&#125;/** * 首、中、尾三数取中值 min(max(a, b), c) * @param first * @param mid * @param last * @return */private int getMedian(int first, int mid, int last) &#123; if (first &gt; mid) &#123; if (first &gt; last) &#123; if (mid &gt; last) &#123; return mid; &#125; else &#123; return last; &#125; &#125; else &#123; return first; &#125; &#125; else &#123; if (first &gt; last) &#123; return first; &#125; else &#123; if (mid &gt; last) &#123; return last; &#125; else &#123; return mid; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉堆]]></title>
    <url>%2F2018%2F08%2F17%2F%E4%BA%8C%E5%8F%89%E5%A0%86%2F</url>
    <content type="text"><![CDATA[二叉堆是一种特殊的堆，是一棵完全二叉树。 特性： 完全二叉树 最大堆：父节点总是大于等于子节点；最小堆：父节点总是小于等于子节点 二叉堆常用数组实现。并且对于数组中的任意位置i上的元素，其左儿子在位置2i上，其右儿子在左儿子后的2i+1上，其父节点在i/2取整数的位置上。（注意：根节点的位置是1，数组从1位置开始排列，0位置为空） 插入二叉堆插入的过程是一个上滤的过程。 将新节点插入到完全二叉树中的最后 与父节点进行比较，当小于父节点时，跟父节点互换，此时新节点上移（假设为最小堆） 直到大于父节点，插入完成 插入 1234567891011121314151617public void insert(T t) &#123; // 添加到数组末尾 list.add(t); // 上滤 for (int i = list.size(); i &gt; 0; i /= 2) &#123; // 获取父节点 int pi = (i / 2) - 1 &lt; 0 ? 0 : (i / 2) - 1; T p = list.get(pi); // 比较 if (p.compareTo(t) &lt;= 0) &#123; break; &#125; // 与父节点位置交换 list.set(pi, t); list.set(i - 1, p); &#125;&#125; 删除二叉堆每次删除都是删除根节点，通过下滤来调整结构。 删除根节点元素，此时根节点为空节点 比较空节点的两个子节点大小，选择较小的子节点与空节点进行交换，此时空节点下移（假设为最小堆） 当空节点下移到叶子节点后，将完全二叉树中的最后一个元素移到空节点 删除 123456789101112131415161718192021222324252627282930313233343536373839404142public T delete() &#123; // 删除根节点 T del = list.get(0); // 将最后一个节点设置为根节点 T last = list.remove(list.size() - 1); if (list.size() != 0) &#123; // 下滤 int i = 0; list.set(i, last); while (i &lt; list.size()) &#123; int min = getMinChildIndex(i); T t = list.get(min); if (i != min &amp;&amp; last.compareTo(t) &gt; 0) &#123; list.set(i, t); list.set(min, last); i = min; &#125; else &#123; break; &#125; &#125; &#125; return del;&#125;/** * 根据父节点索引，获取其最小子节点的索引，若没有子节点，则返回父节点索引 * @param index * @return */private int getMinChildIndex(int index) &#123; int left = (index + 1) * 2 - 1; int right = (index + 1) * 2; if (left &lt; list.size() &amp;&amp; right &lt; list.size()) &#123; if (list.get(left).compareTo(list.get(right)) &gt; 0) &#123; return right; &#125; else &#123; return left; &#125; &#125; else &#123; return index; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红黑树]]></title>
    <url>%2F2018%2F08%2F17%2F%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[红黑树是具有着色性质的二叉查找树。平均红黑树和评级AVL树一样深，从而查找时间一般接近最优。同时红黑树执行插入操作时，产生的旋转相对较少，性能更优。 特性 每一个节点或者是红色，或者是黑色 根是黑色 如果一个节点是红色的，那么它的子节点必须是黑色的 任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等 null节点为黑色 旋转左旋 左旋做了三件事： 将y的左子节点赋给x的右子节点,并将x赋给y左子节点的父节点(y左子节点非空时) 将x的父节点p(非空时)赋给y的父节点，同时更新p的子节点为y(左或右) 将y的左子节点设为x，将x的父节点设为y 右旋 右旋做了三件事： 将x的右子节点赋给y的左子节点,并将y赋给x右子节点的父节点(x右子节点非空时) 将y的父节点p(非空时)赋给x的父节点，同时更新p的子节点为x(左或右) 将x的右子节点设为y，将y的父节点设为x 插入首先，将红黑树当作一颗二叉查找树，将节点插入；然后，将节点着色为红色，这样就不会违背特性4；最后，通过旋转和重新着色等方法来修正该树，使之重新成为一颗红黑树。 新插入的节点分为三种情况： 新插入的节点是根节点，则直接着色为黑色 新插入的节点的父节点是黑色，则不需要做任何操作，就满足红黑树特性 新插入的节点的父节点是红色，则需要进行调整，使得结构满足红黑树特性，此时也有三种情况： 1 当前节点的父节点是红色，并且其叔叔节点也是红色 1、将父节点设为黑色；2、将叔叔节点设为黑色；3、将爷爷节点设为红色；4、将爷爷节点设为当前节点，继续操作 2 当前节点的父节点是红色，叔叔节点是黑色，且当前节点、父节点、爷爷节点成一字型 1、父节点设为黑色，爷爷节点设为红色；2、对爷爷节点进行单旋 3 当前节点的父节点是红色，叔叔节点是黑色，且当前节点、父节点、爷爷节点成之字型 1、将当前节点设为黑色，爷爷节点设为红色；2、对爷爷节点进行双旋 删除删除操作会删除对应的节点，如果是叶子节点就直接删除，如果是非叶子节点，会用对应的中序遍历的后继节点来顶替要删除节点的位置。删除后就需要做删除修复操作，使的树符合红黑树的定义，符合定义的红黑树高度是平衡的。 红黑树的删除操作是最复杂的操作，复杂的地方就在于当删除了黑色节点的时候，如何从兄弟节点去借调节点，以保证树的颜色符合定义。由于红色的兄弟节点是没法借调出黑节点的，这样只能通过选择操作让他上升到父节点，而由于它是红节点，所以它的子节点就是黑的，可以借调。 对于兄弟节点是黑色节点的可以分成3种情况来处理，当所以的兄弟节点的子节点都是黑色节点时，可以直接将兄弟节点变红，这样局部的红黑树颜色是符合定义的。但是整颗树不一定是符合红黑树定义的，需要往上追溯继续调整。 对于兄弟节点的子节点为左红右黑或者 (全部为红，右红左黑)这两种情况，可以先将前面的情况通过选择转换为后一种情况，在后一种情况下，因为兄弟节点为黑，兄弟节点的右节点为红，可以借调出两个节点出来做黑节点，这样就可以保证删除了黑节点，整棵树还是符合红黑树的定义的，因为黑色节点的个数没有改变。 红黑树的删除操作是遇到删除的节点为红色，或者追溯调整到了root节点，这时删除的修复操作完毕。 代码实现https://github.com/fup1990/EasyRPC/blob/master/nameserver/src/main/java/com/gome/fup/easy/rpc/nameserver/data/NodeTree.java]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树]]></title>
    <url>%2F2018%2F08%2F17%2F%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[二叉树二叉树是一棵树，其中每个节点都不能有多于两个的字节点。 二叉查找树对于树中的每一个节点X，它的左子树中所有项的值小于X中的项，而它的右子树中所有项的值大于X中的项。这意味这该树所有的元素可以用某种一致的方式排序。 插入二分法遍历树中的节点，如果新插入的节点X的key不存在，则插入为叶子节点，如果存在则更新。 删除当删除节点X时，需要考虑以下几种情况： 若X是叶子节点：直接删除； 若X有一个子节点：则让X的子节点，代替X成为X父节点的子节点； 若X有两个子节点：让X的右子树的最小的节点Y代替X成为X父节点的子节点，并递归的删除原来的Y节点 如果删除的次数不频繁，可以使用懒惰删除的策略：当一个节点要被删除时，它仍留在树中，只是被标记删除。 遍历 前序排序根结点 —&gt; 左子树 —&gt; 右子树 前序遍历的输出结果：ABDECF 中序排序左子树—&gt; 根结点 —&gt; 右子树 中序遍历的输出结果：DBEAFC 后序排序左子树 —&gt; 右子树 —&gt; 根结点 前序遍历的输出结果：DEBFCA 层序遍历同级节点从左到右，再子节点同级节点从左到右 层序遍历的输出结果：ABCDEF 平衡二叉查找树一棵平衡二叉查找树是其每个节点的左子树和右子树的高度最多差1的二叉查找树。 旋转单旋当新插入节点和其父节点、祖父节点成一条直线时，需要执行单旋操作。单旋分为左旋和右旋。 双旋当新插入节点和其父节点、祖父节点不在一条直线上，成之子型，需要执行双旋操作。根据新插入节点所处的位置，双旋分为： 左-右双旋，即先左旋后右旋 右-左双旋，即先右旋后左旋 插入定义 AVL树：T 新插入节点：X 递归的将X插入到T的相应的子树：t t树中高度较高一侧的子节点：c 插入操作分为几种情况： 插入X之后，t的左右高度差小于2，则表示此次插入没有破坏T的结构； 插入X之后，t的左右高度差等于2 当c是t的左子节点，且X的值小于c的值时，对t进行右旋； 当c是t的左子节点，且X的值大于c小于t时，对t进行左-右双旋； 当c是t的右子节点，且X的值大于c的值时，对t进行左旋； 当c是t的右子节点，且X的值大于t小于c时，对t进行右-左双旋；]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU缓存]]></title>
    <url>%2F2018%2F08%2F16%2FCPU%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[CPU缓存随着CPU的频率不断提升，而内存的访问速度却没有质的突破，为了弥补访问内存的速度慢，充分发挥CPU的计算资源，提高CPU整体吞吐量，在CPU与内存之间引入了一级Cache。 一般来说，一级Cache可以分为一级数据缓存（Data Cache，D-Cache）和一级指令缓存（Instruction Cache，I-Cache）。随着热点数据体积越来越大，一级Cache L1已经不满足发展的要求，引入了二级Cache L2，三级Cache L3。 缓存行CPU缓存是由很多个缓存行组成的。每个缓存行通常是64字节，并且它有效地引用主内存中的一块儿地址，并拷贝主内存对应地址中的数据。缓存行是CPU与主内存数据交换的最小单位。CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个缓存行。 伪共享 数据X、Y、Z被加载到同一Cache Line中，线程A在Core1修改X，线程B在Core2上修改Y。根据MESI大法，假设是Core1是第一个发起操作的CPU核，Core1上的L1 Cache Line由S（共享）状态变成M（修改，脏数据）状态，然后告知其他的CPU核，图例则是Core2，引用同一地址的Cache Line已经无效了；当Core2发起写操作时，首先导致Core1将X写回主存，Cache Line状态由M变为I（无效），而后才是Core2从主存重新读取该地址内容，Cache Line状态由I变成E（独占），最后进行修改Y操作， Cache Line从E变成M。可见多个线程操作在同一Cache Line上的不同数据，相互竞争同一Cache Line，导致线程彼此牵制影响，变成了串行程序，降低了并发性。此时我们则需要将共享在多线程间的数据进行隔离，使他们不在同一个Cache Line上，从而提升多线程的性能。 解决伪共享方案 1、填充方式正确的方式应该将该对象属性分组，将一起变化的放在一组，与其他属性无关的属性放到一组，将不变的属性放到一组。这样当每次对象变化时，不会带动所有的属性重新加载缓存，提升了读取效率。在JDK1.8以前，我们一般是在属性间增加长整型变量来分隔每一组属性。 12345678910public class DataPadding&#123; long a1,a2,a3,a4,a5,a6,a7,a8;//防止与前一个对象产生伪共享 int value; long modifyTime; long b1,b2,b3,b4,b5,b6,b7,b8;//防止不相关变量伪共享; boolean flag; long c1,c2,c3,c4,c5,c6,c7,c8;// long createTime; char key; long d1,d2,d3,d4,d5,d6,d7,d8;//防止与下一个对象产生伪共享 2、Contended注解方式在JDK1.8中，新增了一种注解@sun.misc.Contended，来使各个变量在Cache line中分隔开。注意，jvm需要添加参数-XX:-RestrictContended才能开启此功能。 12345678910111213141516171819202122232425// 类前加上代表整个类的每个变量都会在单独的cache line中@sun.misc.Contended@SuppressWarnings("restriction")public class ContendedData &#123; int value; long modifyTime; boolean flag; long createTime; char key;&#125;或者这种：// 属性前加上时需要加上组标签@SuppressWarnings("restriction")public class ContendedGroupData &#123; @sun.misc.Contended("group1") int value; @sun.misc.Contended("group1") long modifyTime; @sun.misc.Contended("group2") boolean flag; @sun.misc.Contended("group3") long createTime; @sun.misc.Contended("group3") char key;&#125;]]></content>
      <categories>
        <category>操作系统原理</category>
      </categories>
      <tags>
        <tag>性能</tag>
        <tag>操作系统原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2018%2F08%2F16%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[ExecutorEexecutor作为灵活且强大的异步执行框架，其支持多种不同类型的任务执行策略，提供了一种标准的方法将任务的提交过程和执行过程解耦开发，基于生产者-消费者模式，其提交任务的线程相当于生产者，执行任务的线程相当于消费者，并用Runnable来表示任务，Executor的实现还提供了对生命周期的支持，以及统计信息收集，应用程序管理机制和性能监视等机制。 ExecutorServiceExecutorService是Executor直接的扩展接口，也是最常用的线程池接口，我们通常见到的线程池定时任务线程池都是它的实现类。 ThreadPoolExecutorjava的线程池支持主要通过ThreadPoolExecutor来实现，我们使用的ExecutorService的各种线程池策略都是基于ThreadPoolExecutor实现的，所以ThreadPoolExecutor十分重要。要弄明白各种线程池策略，必须先弄明白ThreadPoolExecutor。 构造参数说明1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 参数说明： corePoolSize：核心线程数，如果运行的线程少于corePoolSize，则创建新线程来执行新任务，即使线程池中的其他线程是空闲的。 maximumPoolSize：最大线程数，可允许创建的线程数。 keepAliveTime：如果线程数多于corePoolSize,则这些多余的线程的空闲时间超过keepAliveTime时将被终止。 unit：keepAliveTime参数的时间单位。 workQueue：保存任务的阻塞队列。 当运行的线程数少于corePoolSize时，在有新任务时直接创建新线程来执行任务而无需再进队列 ； 当运行的线程数等于或多于corePoolSize，在有新任务添加时则选加入队列，不直接创建线程 ； 当队列满时，在有新任务时就创建新线程。 threadFactory：使用ThreadFactory创建新线程，默认使用defaultThreadFactory创建线程。 handler： 定义处理被拒绝任务的策略，默认使用 ThreadPoolExecutor.AbortPolicy， 抛出RejectExecutorException。 执行任务流程 拒绝策略 ThreadPoolExecutor.AbortPolicy：默认策略，抛出RejectExecutorException。 ThreadPoolExecutor.CallerRunsPolicy：改为本地线程同步执行任务。 ThreadPoolExecutor.DiscardPolicy：丢弃任务。 ThreadPoolExecutor.DiscardOldestPolicy：从阻塞队列中取出队首的任务丢弃，然后推入队列。 生命周期 RUNNING：初始状态，接受新任务并且处理已经在队列中的任务。 SHUTDOWN：不接受新任务，但处理队列中的任务。 STOP：不接受新任务，不处理排队的任务，并中断正在进行的任务。 TIDYING：所有任务已终止，workerCount为零，线程转换到状态TIDYING，这时回调terminate()方法。 TERMINATED：终态，terminated()执行完成。 shutdown()：平缓的关闭。不再接受新的任务，同事等待已经提交的任务执行完成，包括未执行的任务。 shutdownNow()：暴力的关闭。取消所有运行中的任务，并且不再执行队列中尚未执行的任务。 ExecutorsExecutors提供了一系列静态工厂方法用于创建各种线程池。 newFixedThreadPool创建一个固定长度的线程池，每当提交一次任务时就创建一个线程，直到达到线程池的最大数量，这时线程池的规模将不再变化。 1234567public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; corePoolSize与 maximumPoolSize数量相等，表示线程池将维护固定数量的线程。使用了无界的 LinkedBlockingQueue队列，所以可以一直添加新任务到线程池，不会触发拒绝机制。 newCachedThreadPool创建一个可换成的线程池，如果线程池的当前规模超过了需要处理的任务数量时，那么将回收空闲的线程；而当 需要处理的任务数量增加时，则添加新的线程。线程池的规模不存在任何限制。 1234567public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; corePoolSize为0， maximumPoolSize为 Integer.MAX_VALUE表示线程池容量为无限。闲置60秒的线程将被回收。 SynchronousQueue是一个阻塞的同步队列， 队列只能存储一个元素。因此，线程池会不断创建新的线程，极端场景下会因为线程数量过多而耗尽计算机资源。 newSingleThreadExecutor一个单线程的Executor，创建单个工作线程来执行任务；如果线程异常，则创建另一个线程来替代。 12345678public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; newScheduledThreadPool创建一个固定长度的线程池，而且以延迟或定时的方式来执行任务。 1234public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); &#125; ScheduledExecutorServiceScheduledExecutorService一种安排任务执行的ExecutorService，任务可以延迟执行，或者在一个固定的时间间隔内重复执行。 12//创建定时器线程池ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1); 常用方法 方法说明 重要参数说明 schedule(Runnable command, long delay, TimeUnit unit) 延后指定时间执行任务 delay:延后指定时间执行任务 scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) 周期的执行任务，一次只能执行一个任务，当前一个任务没有执行完，而周期时间到了，则下一个任务等待前一个任务执行完毕之后立即执行 initialDelay:延后指定时间执行任务；period:定期执行 scheduleWithFixedDelay(Runnable command, long initialDelay, long period, TimeUnit unit) 周期的执行任务，当前一个任务执行完毕后，开始计时 initialDelay:延后指定时间执行任务；period:定期执行 设置线程池的大小设置线程池的大小时，应避免过大或过小这两种极端情况。如果线程池过大，那么大量的线程将在相对很少的CPU和内存资源上发生竞争，降低系统性能，耗费服务器资源。如果线程池过小，那么将导致许多空闲的处理器无法执行工作，浪费资源。要想正确的设置线程池的大小，需要分析计算㕂、资源预算和任务特性。 对于计算密集型任务123N = 线程数量C = CPU数量N = C + 1 对于IO密集型任务123456N = 线程数量C = CPU数量P = CPU利用率CT = 计算时间WT = IO等待时间N = C * P * (1 + CT/WT) 当然，CPU周期并不是唯一影响线程池大小饿资源，还包括内存、文件句柄、套接字句柄和数据库连接等。计算这些资源对线程池的约束条件是更容易的：计算每个任务对该资源的需求量，然后用该资源的可用总量除以每个任务的需求量，所得结果就是线程池大小的上线。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>线程池</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap]]></title>
    <url>%2F2018%2F08%2F16%2FHashMap%2F</url>
    <content type="text"><![CDATA[概要HashMap 是一个关联数组、哈希表，它是线程不安全的，允许key为null,value为null。遍历时无序。 其底层数据结构是数组称之为哈希桶，每个桶里面放的是链表，链表中的每个节点，就是哈希表中的每个元素。 在JDK8中，当链表长度达到8，会转化成红黑树，以提升它的查询、插入效率，它实现了Map&lt;K,V&gt;, Cloneable, Serializable接口。 数据结构 构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384//最大容量 2的30次方static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认的加载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;//哈希桶，存放链表。 长度是2的N次方，或者初始化时为0.transient Node&lt;K,V&gt;[] table;//加载因子，用于计算哈希表元素数量的阈值。 threshold = 哈希桶.length * loadFactor;final float loadFactor;//哈希表内元素数量的阈值，当哈希表内元素数量超过阈值时，会发生扩容resize()。int threshold;public HashMap() &#123; //默认构造函数，赋值加载因子为默认的0.75f this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;public HashMap(int initialCapacity) &#123; //指定初始化容量的构造函数 this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;//同时指定初始化容量 以及 加载因子， 用的很少，一般不会修改loadFactorpublic HashMap(int initialCapacity, float loadFactor) &#123; //边界处理 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); //初始容量最大不能超过2的30次方 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //显然加载因子不能为负数 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; //设置阈值为 》=初始化容量的 2的n次方的值 this.threshold = tableSizeFor(initialCapacity);&#125;//新建一个哈希表，同时将另一个map m 里的所有元素加入表中public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125;//根据期望容量cap，返回2的n次方形式的 哈希桶的实际容量 length。 返回值一般会&gt;=cap static final int tableSizeFor(int cap) &#123;//经过下面的 或 和位移 运算， n最终各位都是1。 int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; //判断n是否越界，返回 2的n次方作为 table（哈希桶）的阈值 return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;//将另一个Map的所有元素加入表中，参数evict初始化时为false，其他情况为truefinal void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; //拿到m的元素数量 int s = m.size(); //如果数量大于0 if (s &gt; 0) &#123; //如果当前表是空的 if (table == null) &#123; // pre-size //根据m的元素数量和当前表的加载因子，计算出阈值 float ft = ((float)s / loadFactor) + 1.0F; //修正阈值的边界 不能超过MAXIMUM_CAPACITY int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); //如果新的阈值大于当前阈值 if (t &gt; threshold) //返回一个 》=新的阈值的 满足2的n次方的阈值 threshold = tableSizeFor(t); &#125; //如果当前元素表不是空的，但是 m的元素数量大于阈值，说明一定要扩容。 else if (s &gt; threshold) resize(); //遍历 m 依次将元素加入当前表中。 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; Node&lt;K,V&gt; Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 扩容当HashMap的容量达到threshold域值时，就会触发扩容。扩容前后，哈希桶的长度一定会是2的次方。扩容操作时，会new一个新的Node数组作为哈希桶，然后将原哈希表中的所有数据(Node节点)移动到新的哈希桶中，相当于对原哈希表中所有的数据重新做了一个put操作。所以性能消耗很大，可想而知，在哈希表的容量越大时，性能消耗越明显。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112final Node&lt;K,V&gt;[] resize() &#123; //oldTab 为当前表的哈希桶 Node&lt;K,V&gt;[] oldTab = table; //当前哈希桶的容量 length int oldCap = (oldTab == null) ? 0 : oldTab.length; //当前的阈值 int oldThr = threshold; //初始化新的容量和阈值为0 int newCap, newThr = 0; //如果当前容量大于0 if (oldCap &gt; 0) &#123; //如果当前容量已经到达上限 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //则设置阈值是2的31次方-1 threshold = Integer.MAX_VALUE; //同时返回当前的哈希桶，不再扩容 return oldTab; &#125;//否则新的容量为旧的容量的两倍。 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY)//如果旧的容量大于等于默认初始容量16 //那么新的阈值也等于旧的阈值的两倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125;//如果当前表是空的，但是有阈值。代表是初始化时指定了容量、阈值的情况 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr;//那么新表的容量就等于旧的阈值 else &#123;&#125;//如果当前表是空的，而且也没有阈值。代表是初始化时没有任何容量/阈值参数的情况 // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY;//此时新表的容量为默认的容量 16 //新的阈值为默认容量16 * 默认加载因子0.75f = 12 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123;//如果新的阈值是0，对应的是 当前表是空的，但是有阈值的情况 float ft = (float)newCap * loadFactor;//根据新表容量 和 加载因子 求出新的阈值 //进行越界修复 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //更新阈值 threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) //根据新的容量 构建新的哈希桶 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //更新哈希桶引用 table = newTab; //如果以前的哈希桶中有元素 //下面开始将当前哈希桶中的所有节点转移到新的哈希桶中 if (oldTab != null) &#123; //遍历老的哈希桶 for (int j = 0; j &lt; oldCap; ++j) &#123; //取出当前的节点 e Node&lt;K,V&gt; e; //如果当前桶中有元素,则将链表赋值给e if ((e = oldTab[j]) != null) &#123; //将原哈希桶置空以便GC oldTab[j] = null; //如果当前链表中就一个元素，（没有发生哈希碰撞） if (e.next == null) //直接将这个元素放置在新的哈希桶里。 //注意这里取下标 是用 哈希值 与 桶的长度-1 。 //由于桶的长度是2的n次方，这么做其实是等于 一个模运算。但是效率更高 newTab[e.hash &amp; (newCap - 1)] = e; //如果发生过哈希碰撞 ,而且是节点数超过8个，转化成了红黑树 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //如果发生过哈希碰撞，节点数小于8个。 //则要根据链表上每个节点的哈希值，依次放入新哈希桶对应下标位置。 else &#123; // preserve order //因为扩容是容量翻倍，所以原链表上的每个节点。 //现在可能存放在原来的下标，即low位， 或者扩容后的下标，即high位。 //high位= low位+原哈希桶容量 //低位链表的头结点、尾节点 Node&lt;K,V&gt; loHead = null, loTail = null; //高位链表的头节点、尾节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next;//临时节点 存放e的下一个节点 do &#123; next = e.next; //这里又是一个利用位运算 代替常规运算的高效点： //利用哈希值 与 旧的容量，可以得到哈希值去模后， //是大于等于oldCap还是小于oldCap，等于0代表小于oldCap，应该存放在低位， //否则存放在高位 if ((e.hash &amp; oldCap) == 0) &#123; //给头尾节点指针赋值 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125;//高位也是相同的逻辑 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125;//循环直到链表结束 &#125; while ((e = next) != null); //将低位链表存放在原index处， if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //将高位链表存放在新index处 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; putValue12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; //tab存放 当前的哈希桶， p用作临时链表节点 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果当前哈希表是空的，代表是初始化 if ((tab = table) == null || (n = tab.length) == 0) //那么直接去扩容哈希表，并且将扩容后的哈希桶长度赋值给n n = (tab = resize()).length; //如果当前index的节点是空的，表示没有发生哈希碰撞。 直接构建一个新节点Node，挂载在index处即可。 //这里再啰嗦一下，index 是利用 哈希值 &amp; 哈希桶的长度-1，替代模运算 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123;//否则 发生了哈希冲突。 Node&lt;K,V&gt; e; K k; //如果哈希值相等，key也相等，则是覆盖value操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p;//将当前节点引用赋值给e else if (p instanceof TreeNode)//红黑树 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123;//不是覆盖操作，则插入一个普通链表节点 //遍历链表 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123;//遍历到尾部，追加新节点到尾部 p.next = newNode(hash, key, value, null); //如果追加节点后，链表数量&gt;=8，则转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //如果找到了要覆盖的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果e不是null，说明有需要覆盖的节点， if (e != null) &#123; // existing mapping for key //则覆盖节点值，并返回原oldValue V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; //这是一个空实现的函数，用作LinkedHashMap重写使用。 afterNodeAccess(e); return oldValue; &#125; &#125; //如果执行到了这里，说明插入了一个新的节点，所以会修改modCount，以及返回null。 //修改modCount ++modCount; //更新size，并判断是否需要扩容。 if (++size &gt; threshold) resize(); //这是一个空实现的函数，用作LinkedHashMap重写使用。 afterNodeInsertion(evict); return null;&#125; 小结 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。 HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。 红黑树大程度优化了HashMap的性能。]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>源码</tag>
        <tag>集合</tag>
      </tags>
  </entry>
</search>
